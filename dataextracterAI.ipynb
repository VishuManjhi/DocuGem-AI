{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b58d8b13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain\n",
      "  Downloading langchain-0.3.26-py3-none-any.whl.metadata (7.8 kB)\n",
      "Collecting langchain-community\n",
      "  Downloading langchain_community-0.3.27-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting pypdf\n",
      "  Downloading pypdf-5.7.0-py3-none-any.whl.metadata (7.2 kB)\n",
      "Collecting langchain-openai\n",
      "  Downloading langchain_openai-0.3.27-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting chromadb\n",
      "  Downloading chromadb-1.0.15-cp39-abi3-win_amd64.whl.metadata (7.1 kB)\n",
      "Collecting pandas\n",
      "  Downloading pandas-2.3.1-cp313-cp313-win_amd64.whl.metadata (19 kB)\n",
      "Collecting streamlit\n",
      "  Downloading streamlit-1.46.1-py3-none-any.whl.metadata (9.0 kB)\n",
      "Collecting python-dotenv\n",
      "  Downloading python_dotenv-1.1.1-py3-none-any.whl.metadata (24 kB)\n",
      "Collecting langchain-core<1.0.0,>=0.3.66 (from langchain)\n",
      "  Downloading langchain_core-0.3.68-py3-none-any.whl.metadata (5.8 kB)\n",
      "Collecting langchain-text-splitters<1.0.0,>=0.3.8 (from langchain)\n",
      "  Downloading langchain_text_splitters-0.3.8-py3-none-any.whl.metadata (1.9 kB)\n",
      "Collecting langsmith>=0.1.17 (from langchain)\n",
      "  Downloading langsmith-0.4.5-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting pydantic<3.0.0,>=2.7.4 (from langchain)\n",
      "  Downloading pydantic-2.11.7-py3-none-any.whl.metadata (67 kB)\n",
      "Collecting SQLAlchemy<3,>=1.4 (from langchain)\n",
      "  Downloading sqlalchemy-2.0.41-cp313-cp313-win_amd64.whl.metadata (9.8 kB)\n",
      "Collecting requests<3,>=2 (from langchain)\n",
      "  Downloading requests-2.32.4-py3-none-any.whl.metadata (4.9 kB)\n",
      "Collecting PyYAML>=5.3 (from langchain)\n",
      "  Downloading PyYAML-6.0.2-cp313-cp313-win_amd64.whl.metadata (2.1 kB)\n",
      "Collecting tenacity!=8.4.0,<10.0.0,>=8.1.0 (from langchain-core<1.0.0,>=0.3.66->langchain)\n",
      "  Downloading tenacity-9.1.2-py3-none-any.whl.metadata (1.2 kB)\n",
      "Collecting jsonpatch<2.0,>=1.33 (from langchain-core<1.0.0,>=0.3.66->langchain)\n",
      "  Downloading jsonpatch-1.33-py2.py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting packaging<25,>=23.2 (from langchain-core<1.0.0,>=0.3.66->langchain)\n",
      "  Downloading packaging-24.2-py3-none-any.whl.metadata (3.2 kB)\n",
      "Collecting typing-extensions>=4.7 (from langchain-core<1.0.0,>=0.3.66->langchain)\n",
      "  Downloading typing_extensions-4.14.1-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting jsonpointer>=1.9 (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.66->langchain)\n",
      "  Downloading jsonpointer-3.0.0-py2.py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting annotated-types>=0.6.0 (from pydantic<3.0.0,>=2.7.4->langchain)\n",
      "  Downloading annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting pydantic-core==2.33.2 (from pydantic<3.0.0,>=2.7.4->langchain)\n",
      "  Downloading pydantic_core-2.33.2-cp313-cp313-win_amd64.whl.metadata (6.9 kB)\n",
      "Collecting typing-inspection>=0.4.0 (from pydantic<3.0.0,>=2.7.4->langchain)\n",
      "  Downloading typing_inspection-0.4.1-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting charset_normalizer<4,>=2 (from requests<3,>=2->langchain)\n",
      "  Downloading charset_normalizer-3.4.2-cp313-cp313-win_amd64.whl.metadata (36 kB)\n",
      "Collecting idna<4,>=2.5 (from requests<3,>=2->langchain)\n",
      "  Downloading idna-3.10-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting urllib3<3,>=1.21.1 (from requests<3,>=2->langchain)\n",
      "  Downloading urllib3-2.5.0-py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting certifi>=2017.4.17 (from requests<3,>=2->langchain)\n",
      "  Downloading certifi-2025.7.9-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting greenlet>=1 (from SQLAlchemy<3,>=1.4->langchain)\n",
      "  Downloading greenlet-3.2.3-cp313-cp313-win_amd64.whl.metadata (4.2 kB)\n",
      "Collecting aiohttp<4.0.0,>=3.8.3 (from langchain-community)\n",
      "  Downloading aiohttp-3.12.14-cp313-cp313-win_amd64.whl.metadata (7.9 kB)\n",
      "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain-community)\n",
      "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
      "Collecting pydantic-settings<3.0.0,>=2.4.0 (from langchain-community)\n",
      "  Downloading pydantic_settings-2.10.1-py3-none-any.whl.metadata (3.4 kB)\n",
      "Collecting httpx-sse<1.0.0,>=0.4.0 (from langchain-community)\n",
      "  Downloading httpx_sse-0.4.1-py3-none-any.whl.metadata (9.4 kB)\n",
      "Collecting numpy>=2.1.0 (from langchain-community)\n",
      "  Downloading numpy-2.3.1-cp313-cp313-win_amd64.whl.metadata (60 kB)\n",
      "Collecting aiohappyeyeballs>=2.5.0 (from aiohttp<4.0.0,>=3.8.3->langchain-community)\n",
      "  Downloading aiohappyeyeballs-2.6.1-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting aiosignal>=1.4.0 (from aiohttp<4.0.0,>=3.8.3->langchain-community)\n",
      "  Downloading aiosignal-1.4.0-py3-none-any.whl.metadata (3.7 kB)\n",
      "Collecting attrs>=17.3.0 (from aiohttp<4.0.0,>=3.8.3->langchain-community)\n",
      "  Downloading attrs-25.3.0-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp<4.0.0,>=3.8.3->langchain-community)\n",
      "  Downloading frozenlist-1.7.0-cp313-cp313-win_amd64.whl.metadata (19 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp<4.0.0,>=3.8.3->langchain-community)\n",
      "  Downloading multidict-6.6.3-cp313-cp313-win_amd64.whl.metadata (5.4 kB)\n",
      "Collecting propcache>=0.2.0 (from aiohttp<4.0.0,>=3.8.3->langchain-community)\n",
      "  Downloading propcache-0.3.2-cp313-cp313-win_amd64.whl.metadata (12 kB)\n",
      "Collecting yarl<2.0,>=1.17.0 (from aiohttp<4.0.0,>=3.8.3->langchain-community)\n",
      "  Downloading yarl-1.20.1-cp313-cp313-win_amd64.whl.metadata (76 kB)\n",
      "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
      "  Downloading marshmallow-3.26.1-py3-none-any.whl.metadata (7.3 kB)\n",
      "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
      "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
      "  Downloading mypy_extensions-1.1.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "Collecting openai<2.0.0,>=1.86.0 (from langchain-openai)\n",
      "  Downloading openai-1.95.1-py3-none-any.whl.metadata (29 kB)\n",
      "Collecting tiktoken<1,>=0.7 (from langchain-openai)\n",
      "  Downloading tiktoken-0.9.0-cp313-cp313-win_amd64.whl.metadata (6.8 kB)\n",
      "Collecting anyio<5,>=3.5.0 (from openai<2.0.0,>=1.86.0->langchain-openai)\n",
      "  Downloading anyio-4.9.0-py3-none-any.whl.metadata (4.7 kB)\n",
      "Collecting distro<2,>=1.7.0 (from openai<2.0.0,>=1.86.0->langchain-openai)\n",
      "  Downloading distro-1.9.0-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting httpx<1,>=0.23.0 (from openai<2.0.0,>=1.86.0->langchain-openai)\n",
      "  Downloading httpx-0.28.1-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting jiter<1,>=0.4.0 (from openai<2.0.0,>=1.86.0->langchain-openai)\n",
      "  Downloading jiter-0.10.0-cp313-cp313-win_amd64.whl.metadata (5.3 kB)\n",
      "Collecting sniffio (from openai<2.0.0,>=1.86.0->langchain-openai)\n",
      "  Downloading sniffio-1.3.1-py3-none-any.whl.metadata (3.9 kB)\n",
      "Collecting tqdm>4 (from openai<2.0.0,>=1.86.0->langchain-openai)\n",
      "  Downloading tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai<2.0.0,>=1.86.0->langchain-openai)\n",
      "  Downloading httpcore-1.0.9-py3-none-any.whl.metadata (21 kB)\n",
      "Collecting h11>=0.16 (from httpcore==1.*->httpx<1,>=0.23.0->openai<2.0.0,>=1.86.0->langchain-openai)\n",
      "  Downloading h11-0.16.0-py3-none-any.whl.metadata (8.3 kB)\n",
      "Collecting regex>=2022.1.18 (from tiktoken<1,>=0.7->langchain-openai)\n",
      "  Downloading regex-2024.11.6-cp313-cp313-win_amd64.whl.metadata (41 kB)\n",
      "Collecting build>=1.0.3 (from chromadb)\n",
      "  Downloading build-1.2.2.post1-py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting pybase64>=1.4.1 (from chromadb)\n",
      "  Downloading pybase64-1.4.1-cp313-cp313-win_amd64.whl.metadata (8.7 kB)\n",
      "Collecting uvicorn>=0.18.3 (from uvicorn[standard]>=0.18.3->chromadb)\n",
      "  Downloading uvicorn-0.35.0-py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting posthog<6.0.0,>=2.4.0 (from chromadb)\n",
      "  Downloading posthog-5.4.0-py3-none-any.whl.metadata (5.7 kB)\n",
      "Collecting onnxruntime>=1.14.1 (from chromadb)\n",
      "  Downloading onnxruntime-1.22.1-cp313-cp313-win_amd64.whl.metadata (5.1 kB)\n",
      "Collecting opentelemetry-api>=1.2.0 (from chromadb)\n",
      "  Downloading opentelemetry_api-1.35.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting opentelemetry-exporter-otlp-proto-grpc>=1.2.0 (from chromadb)\n",
      "  Downloading opentelemetry_exporter_otlp_proto_grpc-1.35.0-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting opentelemetry-sdk>=1.2.0 (from chromadb)\n",
      "  Downloading opentelemetry_sdk-1.35.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting tokenizers>=0.13.2 (from chromadb)\n",
      "  Downloading tokenizers-0.21.2-cp39-abi3-win_amd64.whl.metadata (6.9 kB)\n",
      "Collecting pypika>=0.48.9 (from chromadb)\n",
      "  Downloading PyPika-0.48.9.tar.gz (67 kB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Collecting overrides>=7.3.1 (from chromadb)\n",
      "  Downloading overrides-7.7.0-py3-none-any.whl.metadata (5.8 kB)\n",
      "Collecting importlib-resources (from chromadb)\n",
      "  Downloading importlib_resources-6.5.2-py3-none-any.whl.metadata (3.9 kB)\n",
      "Collecting grpcio>=1.58.0 (from chromadb)\n",
      "  Downloading grpcio-1.73.1-cp313-cp313-win_amd64.whl.metadata (4.0 kB)\n",
      "Collecting bcrypt>=4.0.1 (from chromadb)\n",
      "  Downloading bcrypt-4.3.0-cp39-abi3-win_amd64.whl.metadata (10 kB)\n",
      "Collecting typer>=0.9.0 (from chromadb)\n",
      "  Downloading typer-0.16.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting kubernetes>=28.1.0 (from chromadb)\n",
      "  Downloading kubernetes-33.1.0-py2.py3-none-any.whl.metadata (1.7 kB)\n",
      "Collecting mmh3>=4.0.1 (from chromadb)\n",
      "  Downloading mmh3-5.1.0-cp313-cp313-win_amd64.whl.metadata (16 kB)\n",
      "Collecting orjson>=3.9.12 (from chromadb)\n",
      "  Downloading orjson-3.10.18-cp313-cp313-win_amd64.whl.metadata (43 kB)\n",
      "Collecting rich>=10.11.0 (from chromadb)\n",
      "  Downloading rich-14.0.0-py3-none-any.whl.metadata (18 kB)\n",
      "Collecting jsonschema>=4.19.0 (from chromadb)\n",
      "  Downloading jsonschema-4.24.0-py3-none-any.whl.metadata (7.8 kB)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\vishumanjhi\\desktop\\evy\\ai data extracter\\venv\\lib\\site-packages (from posthog<6.0.0,>=2.4.0->chromadb) (1.17.0)\n",
      "Requirement already satisfied: python-dateutil>=2.2 in c:\\users\\vishumanjhi\\desktop\\evy\\ai data extracter\\venv\\lib\\site-packages (from posthog<6.0.0,>=2.4.0->chromadb) (2.9.0.post0)\n",
      "Collecting backoff>=1.10.0 (from posthog<6.0.0,>=2.4.0->chromadb)\n",
      "  Downloading backoff-2.2.1-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting pytz>=2020.1 (from pandas)\n",
      "  Downloading pytz-2025.2-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting tzdata>=2022.7 (from pandas)\n",
      "  Downloading tzdata-2025.2-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting altair<6,>=4.0 (from streamlit)\n",
      "  Downloading altair-5.5.0-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting blinker<2,>=1.5.0 (from streamlit)\n",
      "  Downloading blinker-1.9.0-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting cachetools<7,>=4.0 (from streamlit)\n",
      "  Downloading cachetools-6.1.0-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting click<9,>=7.0 (from streamlit)\n",
      "  Downloading click-8.2.1-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting pillow<12,>=7.1.0 (from streamlit)\n",
      "  Downloading pillow-11.3.0-cp313-cp313-win_amd64.whl.metadata (9.2 kB)\n",
      "Collecting protobuf<7,>=3.20 (from streamlit)\n",
      "  Downloading protobuf-6.31.1-cp310-abi3-win_amd64.whl.metadata (593 bytes)\n",
      "Collecting pyarrow>=7.0 (from streamlit)\n",
      "  Downloading pyarrow-20.0.0-cp313-cp313-win_amd64.whl.metadata (3.4 kB)\n",
      "Collecting toml<2,>=0.10.1 (from streamlit)\n",
      "  Downloading toml-0.10.2-py2.py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting watchdog<7,>=2.1.5 (from streamlit)\n",
      "  Downloading watchdog-6.0.0-py3-none-win_amd64.whl.metadata (44 kB)\n",
      "Collecting gitpython!=3.1.19,<4,>=3.0.7 (from streamlit)\n",
      "  Downloading GitPython-3.1.44-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting pydeck<1,>=0.8.0b4 (from streamlit)\n",
      "  Downloading pydeck-0.9.1-py2.py3-none-any.whl.metadata (4.1 kB)\n",
      "Requirement already satisfied: tornado!=6.5.0,<7,>=6.0.3 in c:\\users\\vishumanjhi\\desktop\\evy\\ai data extracter\\venv\\lib\\site-packages (from streamlit) (6.5.1)\n",
      "Collecting jinja2 (from altair<6,>=4.0->streamlit)\n",
      "  Downloading jinja2-3.1.6-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting narwhals>=1.14.2 (from altair<6,>=4.0->streamlit)\n",
      "  Downloading narwhals-1.46.0-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\vishumanjhi\\desktop\\evy\\ai data extracter\\venv\\lib\\site-packages (from click<9,>=7.0->streamlit) (0.4.6)\n",
      "Collecting gitdb<5,>=4.0.1 (from gitpython!=3.1.19,<4,>=3.0.7->streamlit)\n",
      "  Downloading gitdb-4.0.12-py3-none-any.whl.metadata (1.2 kB)\n",
      "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit)\n",
      "  Downloading smmap-5.0.2-py3-none-any.whl.metadata (4.3 kB)\n",
      "Collecting pyproject_hooks (from build>=1.0.3->chromadb)\n",
      "  Downloading pyproject_hooks-1.2.0-py3-none-any.whl.metadata (1.3 kB)\n",
      "Collecting MarkupSafe>=2.0 (from jinja2->altair<6,>=4.0->streamlit)\n",
      "  Downloading MarkupSafe-3.0.2-cp313-cp313-win_amd64.whl.metadata (4.1 kB)\n",
      "Collecting jsonschema-specifications>=2023.03.6 (from jsonschema>=4.19.0->chromadb)\n",
      "  Downloading jsonschema_specifications-2025.4.1-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting referencing>=0.28.4 (from jsonschema>=4.19.0->chromadb)\n",
      "  Downloading referencing-0.36.2-py3-none-any.whl.metadata (2.8 kB)\n",
      "Collecting rpds-py>=0.7.1 (from jsonschema>=4.19.0->chromadb)\n",
      "  Downloading rpds_py-0.26.0-cp313-cp313-win_amd64.whl.metadata (4.3 kB)\n",
      "Collecting google-auth>=1.0.1 (from kubernetes>=28.1.0->chromadb)\n",
      "  Downloading google_auth-2.40.3-py2.py3-none-any.whl.metadata (6.2 kB)\n",
      "Collecting websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 (from kubernetes>=28.1.0->chromadb)\n",
      "  Downloading websocket_client-1.8.0-py3-none-any.whl.metadata (8.0 kB)\n",
      "Collecting requests-oauthlib (from kubernetes>=28.1.0->chromadb)\n",
      "  Downloading requests_oauthlib-2.0.0-py2.py3-none-any.whl.metadata (11 kB)\n",
      "Collecting oauthlib>=3.2.2 (from kubernetes>=28.1.0->chromadb)\n",
      "  Downloading oauthlib-3.3.1-py3-none-any.whl.metadata (7.9 kB)\n",
      "Collecting durationpy>=0.7 (from kubernetes>=28.1.0->chromadb)\n",
      "  Downloading durationpy-0.10-py3-none-any.whl.metadata (340 bytes)\n",
      "Collecting cachetools<7,>=4.0 (from streamlit)\n",
      "  Downloading cachetools-5.5.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting pyasn1-modules>=0.2.1 (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb)\n",
      "  Downloading pyasn1_modules-0.4.2-py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting rsa<5,>=3.1.4 (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb)\n",
      "  Downloading rsa-4.9.1-py3-none-any.whl.metadata (5.6 kB)\n",
      "Collecting pyasn1>=0.1.3 (from rsa<5,>=3.1.4->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb)\n",
      "  Downloading pyasn1-0.6.1-py3-none-any.whl.metadata (8.4 kB)\n",
      "Collecting requests-toolbelt<2.0.0,>=1.0.0 (from langsmith>=0.1.17->langchain)\n",
      "  Downloading requests_toolbelt-1.0.0-py2.py3-none-any.whl.metadata (14 kB)\n",
      "Collecting zstandard<0.24.0,>=0.23.0 (from langsmith>=0.1.17->langchain)\n",
      "  Downloading zstandard-0.23.0-cp313-cp313-win_amd64.whl.metadata (3.0 kB)\n",
      "Collecting coloredlogs (from onnxruntime>=1.14.1->chromadb)\n",
      "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
      "Collecting flatbuffers (from onnxruntime>=1.14.1->chromadb)\n",
      "  Downloading flatbuffers-25.2.10-py2.py3-none-any.whl.metadata (875 bytes)\n",
      "Collecting sympy (from onnxruntime>=1.14.1->chromadb)\n",
      "  Downloading sympy-1.14.0-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting importlib-metadata<8.8.0,>=6.0 (from opentelemetry-api>=1.2.0->chromadb)\n",
      "  Downloading importlib_metadata-8.7.0-py3-none-any.whl.metadata (4.8 kB)\n",
      "Collecting zipp>=3.20 (from importlib-metadata<8.8.0,>=6.0->opentelemetry-api>=1.2.0->chromadb)\n",
      "  Downloading zipp-3.23.0-py3-none-any.whl.metadata (3.6 kB)\n",
      "Collecting googleapis-common-protos~=1.57 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb)\n",
      "  Downloading googleapis_common_protos-1.70.0-py3-none-any.whl.metadata (9.3 kB)\n",
      "Collecting opentelemetry-exporter-otlp-proto-common==1.35.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb)\n",
      "  Downloading opentelemetry_exporter_otlp_proto_common-1.35.0-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting opentelemetry-proto==1.35.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb)\n",
      "  Downloading opentelemetry_proto-1.35.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting opentelemetry-semantic-conventions==0.56b0 (from opentelemetry-sdk>=1.2.0->chromadb)\n",
      "  Downloading opentelemetry_semantic_conventions-0.56b0-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting markdown-it-py>=2.2.0 (from rich>=10.11.0->chromadb)\n",
      "  Downloading markdown_it_py-3.0.0-py3-none-any.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\vishumanjhi\\desktop\\evy\\ai data extracter\\venv\\lib\\site-packages (from rich>=10.11.0->chromadb) (2.19.2)\n",
      "Collecting mdurl~=0.1 (from markdown-it-py>=2.2.0->rich>=10.11.0->chromadb)\n",
      "  Downloading mdurl-0.1.2-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting huggingface-hub<1.0,>=0.16.4 (from tokenizers>=0.13.2->chromadb)\n",
      "  Downloading huggingface_hub-0.33.4-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting filelock (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb)\n",
      "  Downloading filelock-3.18.0-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting fsspec>=2023.5.0 (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb)\n",
      "  Downloading fsspec-2025.5.1-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting shellingham>=1.3.0 (from typer>=0.9.0->chromadb)\n",
      "  Downloading shellingham-1.5.4-py2.py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting httptools>=0.6.3 (from uvicorn[standard]>=0.18.3->chromadb)\n",
      "  Downloading httptools-0.6.4-cp313-cp313-win_amd64.whl.metadata (3.7 kB)\n",
      "Collecting watchfiles>=0.13 (from uvicorn[standard]>=0.18.3->chromadb)\n",
      "  Downloading watchfiles-1.1.0-cp313-cp313-win_amd64.whl.metadata (5.0 kB)\n",
      "Collecting websockets>=10.4 (from uvicorn[standard]>=0.18.3->chromadb)\n",
      "  Downloading websockets-15.0.1-cp313-cp313-win_amd64.whl.metadata (7.0 kB)\n",
      "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime>=1.14.1->chromadb)\n",
      "  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
      "Collecting pyreadline3 (from humanfriendly>=9.1->coloredlogs->onnxruntime>=1.14.1->chromadb)\n",
      "  Downloading pyreadline3-3.5.4-py3-none-any.whl.metadata (4.7 kB)\n",
      "Collecting mpmath<1.4,>=1.1.0 (from sympy->onnxruntime>=1.14.1->chromadb)\n",
      "  Downloading mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
      "Downloading langchain-0.3.26-py3-none-any.whl (1.0 MB)\n",
      "   ---------------------------------------- 0.0/1.0 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.0/1.0 MB 12.2 MB/s eta 0:00:00\n",
      "Downloading langchain_core-0.3.68-py3-none-any.whl (441 kB)\n",
      "Downloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
      "Downloading langchain_text_splitters-0.3.8-py3-none-any.whl (32 kB)\n",
      "Downloading packaging-24.2-py3-none-any.whl (65 kB)\n",
      "Downloading pydantic-2.11.7-py3-none-any.whl (444 kB)\n",
      "Downloading pydantic_core-2.33.2-cp313-cp313-win_amd64.whl (2.0 MB)\n",
      "   ---------------------------------------- 0.0/2.0 MB ? eta -:--:--\n",
      "   ---------------------------------------- 2.0/2.0 MB 31.4 MB/s eta 0:00:00\n",
      "Downloading requests-2.32.4-py3-none-any.whl (64 kB)\n",
      "Downloading charset_normalizer-3.4.2-cp313-cp313-win_amd64.whl (105 kB)\n",
      "Downloading idna-3.10-py3-none-any.whl (70 kB)\n",
      "Downloading sqlalchemy-2.0.41-cp313-cp313-win_amd64.whl (2.1 MB)\n",
      "   ---------------------------------------- 0.0/2.1 MB ? eta -:--:--\n",
      "   ---------------------------------------- 2.1/2.1 MB 33.4 MB/s eta 0:00:00\n",
      "Downloading tenacity-9.1.2-py3-none-any.whl (28 kB)\n",
      "Downloading urllib3-2.5.0-py3-none-any.whl (129 kB)\n",
      "Downloading langchain_community-0.3.27-py3-none-any.whl (2.5 MB)\n",
      "   ---------------------------------------- 0.0/2.5 MB ? eta -:--:--\n",
      "   ---------------------------------------- 2.5/2.5 MB 37.0 MB/s eta 0:00:00\n",
      "Downloading aiohttp-3.12.14-cp313-cp313-win_amd64.whl (448 kB)\n",
      "Downloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
      "Downloading httpx_sse-0.4.1-py3-none-any.whl (8.1 kB)\n",
      "Downloading marshmallow-3.26.1-py3-none-any.whl (50 kB)\n",
      "Downloading multidict-6.6.3-cp313-cp313-win_amd64.whl (45 kB)\n",
      "Downloading pydantic_settings-2.10.1-py3-none-any.whl (45 kB)\n",
      "Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
      "Downloading yarl-1.20.1-cp313-cp313-win_amd64.whl (86 kB)\n",
      "Downloading pypdf-5.7.0-py3-none-any.whl (305 kB)\n",
      "Downloading langchain_openai-0.3.27-py3-none-any.whl (70 kB)\n",
      "Downloading openai-1.95.1-py3-none-any.whl (755 kB)\n",
      "   ---------------------------------------- 0.0/755.6 kB ? eta -:--:--\n",
      "   --------------------------------------- 755.6/755.6 kB 28.7 MB/s eta 0:00:00\n",
      "Downloading anyio-4.9.0-py3-none-any.whl (100 kB)\n",
      "Downloading distro-1.9.0-py3-none-any.whl (20 kB)\n",
      "Downloading httpx-0.28.1-py3-none-any.whl (73 kB)\n",
      "Downloading httpcore-1.0.9-py3-none-any.whl (78 kB)\n",
      "Downloading jiter-0.10.0-cp313-cp313-win_amd64.whl (205 kB)\n",
      "Downloading tiktoken-0.9.0-cp313-cp313-win_amd64.whl (894 kB)\n",
      "   ---------------------------------------- 0.0/894.7 kB ? eta -:--:--\n",
      "   --------------------------------------- 894.7/894.7 kB 33.0 MB/s eta 0:00:00\n",
      "Downloading typing_extensions-4.14.1-py3-none-any.whl (43 kB)\n",
      "Downloading chromadb-1.0.15-cp39-abi3-win_amd64.whl (19.5 MB)\n",
      "   ---------------------------------------- 0.0/19.5 MB ? eta -:--:--\n",
      "   ------------------------ --------------- 11.8/19.5 MB 55.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 19.5/19.5 MB 47.8 MB/s eta 0:00:00\n",
      "Downloading posthog-5.4.0-py3-none-any.whl (105 kB)\n",
      "Downloading pandas-2.3.1-cp313-cp313-win_amd64.whl (11.0 MB)\n",
      "   ---------------------------------------- 0.0/11.0 MB ? eta -:--:--\n",
      "   ---------------------- ----------------- 6.3/11.0 MB 31.9 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 10.0/11.0 MB 25.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 11.0/11.0 MB 22.3 MB/s eta 0:00:00\n",
      "Downloading streamlit-1.46.1-py3-none-any.whl (10.1 MB)\n",
      "   ---------------------------------------- 0.0/10.1 MB ? eta -:--:--\n",
      "   ----------- ---------------------------- 2.9/10.1 MB 14.1 MB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 5.8/10.1 MB 14.2 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 8.9/10.1 MB 14.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 10.1/10.1 MB 13.7 MB/s eta 0:00:00\n",
      "Downloading altair-5.5.0-py3-none-any.whl (731 kB)\n",
      "   ---------------------------------------- 0.0/731.2 kB ? eta -:--:--\n",
      "   --------------------------------------- 731.2/731.2 kB 12.4 MB/s eta 0:00:00\n",
      "Downloading blinker-1.9.0-py3-none-any.whl (8.5 kB)\n",
      "Downloading click-8.2.1-py3-none-any.whl (102 kB)\n",
      "Downloading GitPython-3.1.44-py3-none-any.whl (207 kB)\n",
      "Downloading gitdb-4.0.12-py3-none-any.whl (62 kB)\n",
      "Downloading numpy-2.3.1-cp313-cp313-win_amd64.whl (12.7 MB)\n",
      "   ---------------------------------------- 0.0/12.7 MB ? eta -:--:--\n",
      "   --------- ------------------------------ 3.1/12.7 MB 14.9 MB/s eta 0:00:01\n",
      "   ------------------- -------------------- 6.3/12.7 MB 15.0 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 9.4/12.7 MB 15.1 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 12.3/12.7 MB 15.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 12.7/12.7 MB 14.7 MB/s eta 0:00:00\n",
      "Downloading pillow-11.3.0-cp313-cp313-win_amd64.whl (7.0 MB)\n",
      "   ---------------------------------------- 0.0/7.0 MB ? eta -:--:--\n",
      "   ------------------ --------------------- 3.1/7.0 MB 15.4 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 6.6/7.0 MB 15.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 7.0/7.0 MB 15.2 MB/s eta 0:00:00\n",
      "Downloading protobuf-6.31.1-cp310-abi3-win_amd64.whl (435 kB)\n",
      "Downloading pydeck-0.9.1-py2.py3-none-any.whl (6.9 MB)\n",
      "   ---------------------------------------- 0.0/6.9 MB ? eta -:--:--\n",
      "   ------------------ --------------------- 3.1/6.9 MB 15.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  6.8/6.9 MB 16.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 6.9/6.9 MB 15.2 MB/s eta 0:00:00\n",
      "Downloading smmap-5.0.2-py3-none-any.whl (24 kB)\n",
      "Downloading toml-0.10.2-py2.py3-none-any.whl (16 kB)\n",
      "Downloading watchdog-6.0.0-py3-none-win_amd64.whl (79 kB)\n",
      "Downloading python_dotenv-1.1.1-py3-none-any.whl (20 kB)\n",
      "Downloading aiohappyeyeballs-2.6.1-py3-none-any.whl (15 kB)\n",
      "Downloading aiosignal-1.4.0-py3-none-any.whl (7.5 kB)\n",
      "Downloading annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Downloading attrs-25.3.0-py3-none-any.whl (63 kB)\n",
      "Downloading backoff-2.2.1-py3-none-any.whl (15 kB)\n",
      "Downloading bcrypt-4.3.0-cp39-abi3-win_amd64.whl (152 kB)\n",
      "Downloading build-1.2.2.post1-py3-none-any.whl (22 kB)\n",
      "Downloading certifi-2025.7.9-py3-none-any.whl (159 kB)\n",
      "Downloading frozenlist-1.7.0-cp313-cp313-win_amd64.whl (43 kB)\n",
      "Downloading greenlet-3.2.3-cp313-cp313-win_amd64.whl (297 kB)\n",
      "Downloading grpcio-1.73.1-cp313-cp313-win_amd64.whl (4.3 MB)\n",
      "   ---------------------------------------- 0.0/4.3 MB ? eta -:--:--\n",
      "   ----------------------------- ---------- 3.1/4.3 MB 16.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 4.3/4.3 MB 14.9 MB/s eta 0:00:00\n",
      "Downloading h11-0.16.0-py3-none-any.whl (37 kB)\n",
      "Downloading jinja2-3.1.6-py3-none-any.whl (134 kB)\n",
      "Downloading jsonpointer-3.0.0-py2.py3-none-any.whl (7.6 kB)\n",
      "Downloading jsonschema-4.24.0-py3-none-any.whl (88 kB)\n",
      "Downloading jsonschema_specifications-2025.4.1-py3-none-any.whl (18 kB)\n",
      "Downloading kubernetes-33.1.0-py2.py3-none-any.whl (1.9 MB)\n",
      "   ---------------------------------------- 0.0/1.9 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.9/1.9 MB 14.3 MB/s eta 0:00:00\n",
      "Downloading durationpy-0.10-py3-none-any.whl (3.9 kB)\n",
      "Downloading google_auth-2.40.3-py2.py3-none-any.whl (216 kB)\n",
      "Downloading cachetools-5.5.2-py3-none-any.whl (10 kB)\n",
      "Downloading rsa-4.9.1-py3-none-any.whl (34 kB)\n",
      "Downloading langsmith-0.4.5-py3-none-any.whl (367 kB)\n",
      "Downloading orjson-3.10.18-cp313-cp313-win_amd64.whl (134 kB)\n",
      "Downloading requests_toolbelt-1.0.0-py2.py3-none-any.whl (54 kB)\n",
      "Downloading zstandard-0.23.0-cp313-cp313-win_amd64.whl (495 kB)\n",
      "Downloading MarkupSafe-3.0.2-cp313-cp313-win_amd64.whl (15 kB)\n",
      "Downloading mmh3-5.1.0-cp313-cp313-win_amd64.whl (41 kB)\n",
      "Downloading mypy_extensions-1.1.0-py3-none-any.whl (5.0 kB)\n",
      "Downloading narwhals-1.46.0-py3-none-any.whl (373 kB)\n",
      "Downloading oauthlib-3.3.1-py3-none-any.whl (160 kB)\n",
      "Downloading onnxruntime-1.22.1-cp313-cp313-win_amd64.whl (12.7 MB)\n",
      "   ---------------------------------------- 0.0/12.7 MB ? eta -:--:--\n",
      "   --------- ------------------------------ 2.9/12.7 MB 13.9 MB/s eta 0:00:01\n",
      "   ------------------- -------------------- 6.3/12.7 MB 15.3 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 10.0/12.7 MB 16.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 12.7/12.7 MB 15.6 MB/s eta 0:00:00\n",
      "Downloading opentelemetry_api-1.35.0-py3-none-any.whl (65 kB)\n",
      "Downloading importlib_metadata-8.7.0-py3-none-any.whl (27 kB)\n",
      "Downloading opentelemetry_exporter_otlp_proto_grpc-1.35.0-py3-none-any.whl (18 kB)\n",
      "Downloading opentelemetry_exporter_otlp_proto_common-1.35.0-py3-none-any.whl (18 kB)\n",
      "Downloading opentelemetry_proto-1.35.0-py3-none-any.whl (72 kB)\n",
      "Downloading googleapis_common_protos-1.70.0-py3-none-any.whl (294 kB)\n",
      "Downloading opentelemetry_sdk-1.35.0-py3-none-any.whl (119 kB)\n",
      "Downloading opentelemetry_semantic_conventions-0.56b0-py3-none-any.whl (201 kB)\n",
      "Downloading overrides-7.7.0-py3-none-any.whl (17 kB)\n",
      "Downloading propcache-0.3.2-cp313-cp313-win_amd64.whl (40 kB)\n",
      "Downloading pyarrow-20.0.0-cp313-cp313-win_amd64.whl (25.7 MB)\n",
      "   ---------------------------------------- 0.0/25.7 MB ? eta -:--:--\n",
      "   ----- ---------------------------------- 3.4/25.7 MB 16.8 MB/s eta 0:00:02\n",
      "   ---------- ----------------------------- 6.8/25.7 MB 17.1 MB/s eta 0:00:02\n",
      "   ---------------- ----------------------- 10.5/25.7 MB 17.3 MB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 14.2/25.7 MB 17.5 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 17.8/25.7 MB 17.6 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 21.8/25.7 MB 17.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  25.4/25.7 MB 17.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 25.7/25.7 MB 17.3 MB/s eta 0:00:00\n",
      "Downloading pyasn1-0.6.1-py3-none-any.whl (83 kB)\n",
      "Downloading pyasn1_modules-0.4.2-py3-none-any.whl (181 kB)\n",
      "Downloading pybase64-1.4.1-cp313-cp313-win_amd64.whl (36 kB)\n",
      "Downloading pytz-2025.2-py2.py3-none-any.whl (509 kB)\n",
      "Downloading PyYAML-6.0.2-cp313-cp313-win_amd64.whl (156 kB)\n",
      "Downloading referencing-0.36.2-py3-none-any.whl (26 kB)\n",
      "Downloading regex-2024.11.6-cp313-cp313-win_amd64.whl (273 kB)\n",
      "Downloading rich-14.0.0-py3-none-any.whl (243 kB)\n",
      "Downloading markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\n",
      "Downloading mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Downloading rpds_py-0.26.0-cp313-cp313-win_amd64.whl (234 kB)\n",
      "Downloading sniffio-1.3.1-py3-none-any.whl (10 kB)\n",
      "Downloading tokenizers-0.21.2-cp39-abi3-win_amd64.whl (2.5 MB)\n",
      "   ---------------------------------------- 0.0/2.5 MB ? eta -:--:--\n",
      "   ---------------------------------------- 2.5/2.5 MB 17.2 MB/s eta 0:00:00\n",
      "Downloading huggingface_hub-0.33.4-py3-none-any.whl (515 kB)\n",
      "Downloading fsspec-2025.5.1-py3-none-any.whl (199 kB)\n",
      "Downloading tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "Downloading typer-0.16.0-py3-none-any.whl (46 kB)\n",
      "Downloading shellingham-1.5.4-py2.py3-none-any.whl (9.8 kB)\n",
      "Downloading typing_inspection-0.4.1-py3-none-any.whl (14 kB)\n",
      "Downloading tzdata-2025.2-py2.py3-none-any.whl (347 kB)\n",
      "Downloading uvicorn-0.35.0-py3-none-any.whl (66 kB)\n",
      "Downloading httptools-0.6.4-cp313-cp313-win_amd64.whl (87 kB)\n",
      "Downloading watchfiles-1.1.0-cp313-cp313-win_amd64.whl (292 kB)\n",
      "Downloading websocket_client-1.8.0-py3-none-any.whl (58 kB)\n",
      "Downloading websockets-15.0.1-cp313-cp313-win_amd64.whl (176 kB)\n",
      "Downloading zipp-3.23.0-py3-none-any.whl (10 kB)\n",
      "Downloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
      "Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
      "Downloading filelock-3.18.0-py3-none-any.whl (16 kB)\n",
      "Downloading flatbuffers-25.2.10-py2.py3-none-any.whl (30 kB)\n",
      "Downloading importlib_resources-6.5.2-py3-none-any.whl (37 kB)\n",
      "Downloading pyproject_hooks-1.2.0-py3-none-any.whl (10 kB)\n",
      "Downloading pyreadline3-3.5.4-py3-none-any.whl (83 kB)\n",
      "Downloading requests_oauthlib-2.0.0-py2.py3-none-any.whl (24 kB)\n",
      "Downloading sympy-1.14.0-py3-none-any.whl (6.3 MB)\n",
      "   ---------------------------------------- 0.0/6.3 MB ? eta -:--:--\n",
      "   ------------------------ --------------- 3.9/6.3 MB 18.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 6.3/6.3 MB 17.5 MB/s eta 0:00:00\n",
      "Downloading mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "   ---------------------------------------- 0.0/536.2 kB ? eta -:--:--\n",
      "   --------------------------------------- 536.2/536.2 kB 11.1 MB/s eta 0:00:00\n",
      "Building wheels for collected packages: pypika\n",
      "  Building wheel for pypika (pyproject.toml): started\n",
      "  Building wheel for pypika (pyproject.toml): finished with status 'done'\n",
      "  Created wheel for pypika: filename=pypika-0.48.9-py2.py3-none-any.whl size=53916 sha256=822fac8d84a9b74b666ca07bf03e68ac3c004e06a23189f0c151bb16785da031\n",
      "  Stored in directory: c:\\users\\vishumanjhi\\appdata\\local\\pip\\cache\\wheels\\b4\\f8\\a5\\28e9c1524d320f4b8eefdce0e487b5c2e128dbf2ed1bb4a60b\n",
      "Successfully built pypika\n",
      "Installing collected packages: pytz, pypika, mpmath, flatbuffers, durationpy, zstandard, zipp, websockets, websocket-client, watchdog, urllib3, tzdata, typing-extensions, tqdm, toml, tenacity, sympy, sniffio, smmap, shellingham, rpds-py, regex, PyYAML, python-dotenv, pyreadline3, pyproject_hooks, pypdf, pybase64, pyasn1, pyarrow, protobuf, propcache, pillow, packaging, overrides, orjson, oauthlib, numpy, narwhals, mypy-extensions, multidict, mmh3, mdurl, MarkupSafe, jsonpointer, jiter, importlib-resources, idna, httpx-sse, httptools, h11, grpcio, greenlet, fsspec, frozenlist, filelock, distro, click, charset_normalizer, certifi, cachetools, blinker, bcrypt, backoff, attrs, annotated-types, aiohappyeyeballs, yarl, uvicorn, typing-inspection, typing-inspect, SQLAlchemy, rsa, requests, referencing, pydantic-core, pyasn1-modules, pandas, opentelemetry-proto, marshmallow, markdown-it-py, jsonpatch, jinja2, importlib-metadata, humanfriendly, httpcore, googleapis-common-protos, gitdb, build, anyio, aiosignal, watchfiles, tiktoken, rich, requests-toolbelt, requests-oauthlib, pydeck, pydantic, posthog, opentelemetry-exporter-otlp-proto-common, opentelemetry-api, jsonschema-specifications, huggingface-hub, httpx, google-auth, gitpython, dataclasses-json, coloredlogs, aiohttp, typer, tokenizers, pydantic-settings, opentelemetry-semantic-conventions, openai, onnxruntime, langsmith, kubernetes, jsonschema, opentelemetry-sdk, langchain-core, altair, streamlit, opentelemetry-exporter-otlp-proto-grpc, langchain-text-splitters, langchain-openai, langchain, chromadb, langchain-community\n",
      "\n",
      "   ----------------------------------------   0/128 [pytz]\n",
      "   ----------------------------------------   0/128 [pytz]\n",
      "   ----------------------------------------   1/128 [pypika]\n",
      "    ---------------------------------------   2/128 [mpmath]\n",
      "    ---------------------------------------   2/128 [mpmath]\n",
      "    ---------------------------------------   2/128 [mpmath]\n",
      "    ---------------------------------------   2/128 [mpmath]\n",
      "   - --------------------------------------   6/128 [zipp]\n",
      "   -- -------------------------------------   7/128 [websockets]\n",
      "   -- -------------------------------------   8/128 [websocket-client]\n",
      "   --- ------------------------------------  10/128 [urllib3]\n",
      "   --- ------------------------------------  10/128 [urllib3]\n",
      "   --- ------------------------------------  11/128 [tzdata]\n",
      "   --- ------------------------------------  11/128 [tzdata]\n",
      "   --- ------------------------------------  11/128 [tzdata]\n",
      "   ---- -----------------------------------  13/128 [tqdm]\n",
      "   ----- ----------------------------------  16/128 [sympy]\n",
      "   ----- ----------------------------------  16/128 [sympy]\n",
      "   ----- ----------------------------------  16/128 [sympy]\n",
      "   ----- ----------------------------------  16/128 [sympy]\n",
      "   ----- ----------------------------------  16/128 [sympy]\n",
      "   ----- ----------------------------------  16/128 [sympy]\n",
      "   ----- ----------------------------------  16/128 [sympy]\n",
      "   ----- ----------------------------------  16/128 [sympy]\n",
      "   ----- ----------------------------------  16/128 [sympy]\n",
      "   ----- ----------------------------------  16/128 [sympy]\n",
      "   ----- ----------------------------------  16/128 [sympy]\n",
      "   ----- ----------------------------------  16/128 [sympy]\n",
      "   ----- ----------------------------------  16/128 [sympy]\n",
      "   ----- ----------------------------------  16/128 [sympy]\n",
      "   ----- ----------------------------------  16/128 [sympy]\n",
      "   ----- ----------------------------------  16/128 [sympy]\n",
      "   ----- ----------------------------------  16/128 [sympy]\n",
      "   ----- ----------------------------------  16/128 [sympy]\n",
      "   ----- ----------------------------------  16/128 [sympy]\n",
      "   ----- ----------------------------------  16/128 [sympy]\n",
      "   ----- ----------------------------------  16/128 [sympy]\n",
      "   ----- ----------------------------------  16/128 [sympy]\n",
      "   ----- ----------------------------------  16/128 [sympy]\n",
      "   ----- ----------------------------------  16/128 [sympy]\n",
      "   ----- ----------------------------------  16/128 [sympy]\n",
      "   ----- ----------------------------------  16/128 [sympy]\n",
      "   ----- ----------------------------------  16/128 [sympy]\n",
      "   ----- ----------------------------------  16/128 [sympy]\n",
      "   ----- ----------------------------------  16/128 [sympy]\n",
      "   ----- ----------------------------------  16/128 [sympy]\n",
      "   ----- ----------------------------------  16/128 [sympy]\n",
      "   ----- ----------------------------------  16/128 [sympy]\n",
      "   ----- ----------------------------------  16/128 [sympy]\n",
      "   ----- ----------------------------------  16/128 [sympy]\n",
      "   ----- ----------------------------------  16/128 [sympy]\n",
      "   ----- ----------------------------------  16/128 [sympy]\n",
      "   ----- ----------------------------------  16/128 [sympy]\n",
      "   ----- ----------------------------------  16/128 [sympy]\n",
      "   ----- ----------------------------------  16/128 [sympy]\n",
      "   ----- ----------------------------------  16/128 [sympy]\n",
      "   ----- ----------------------------------  16/128 [sympy]\n",
      "   ----- ----------------------------------  16/128 [sympy]\n",
      "   ----- ----------------------------------  16/128 [sympy]\n",
      "   ----- ----------------------------------  16/128 [sympy]\n",
      "   ----- ----------------------------------  16/128 [sympy]\n",
      "   ----- ----------------------------------  16/128 [sympy]\n",
      "   ----- ----------------------------------  16/128 [sympy]\n",
      "   ----- ----------------------------------  16/128 [sympy]\n",
      "   ----- ----------------------------------  16/128 [sympy]\n",
      "   ----- ----------------------------------  16/128 [sympy]\n",
      "   ----- ----------------------------------  16/128 [sympy]\n",
      "   ----- ----------------------------------  16/128 [sympy]\n",
      "   ----- ----------------------------------  16/128 [sympy]\n",
      "   ----- ----------------------------------  16/128 [sympy]\n",
      "   ----- ----------------------------------  16/128 [sympy]\n",
      "   ----- ----------------------------------  16/128 [sympy]\n",
      "   ----- ----------------------------------  16/128 [sympy]\n",
      "   ----- ----------------------------------  16/128 [sympy]\n",
      "   ----- ----------------------------------  16/128 [sympy]\n",
      "   ----- ----------------------------------  16/128 [sympy]\n",
      "   ----- ----------------------------------  16/128 [sympy]\n",
      "   ----- ----------------------------------  18/128 [smmap]\n",
      "   ------ ---------------------------------  21/128 [regex]\n",
      "   ------ ---------------------------------  22/128 [PyYAML]\n",
      "   ------- --------------------------------  24/128 [pyreadline3]\n",
      "   -------- -------------------------------  26/128 [pypdf]\n",
      "   -------- -------------------------------  26/128 [pypdf]\n",
      "   -------- -------------------------------  26/128 [pypdf]\n",
      "   -------- -------------------------------  28/128 [pyasn1]\n",
      "   --------- ------------------------------  29/128 [pyarrow]\n",
      "   --------- ------------------------------  29/128 [pyarrow]\n",
      "   --------- ------------------------------  29/128 [pyarrow]\n",
      "   --------- ------------------------------  29/128 [pyarrow]\n",
      "   --------- ------------------------------  29/128 [pyarrow]\n",
      "   --------- ------------------------------  29/128 [pyarrow]\n",
      "   --------- ------------------------------  29/128 [pyarrow]\n",
      "   --------- ------------------------------  29/128 [pyarrow]\n",
      "   --------- ------------------------------  29/128 [pyarrow]\n",
      "   --------- ------------------------------  29/128 [pyarrow]\n",
      "   --------- ------------------------------  30/128 [protobuf]\n",
      "   --------- ------------------------------  30/128 [protobuf]\n",
      "   ---------- -----------------------------  32/128 [pillow]\n",
      "   ---------- -----------------------------  32/128 [pillow]\n",
      "   ---------- -----------------------------  32/128 [pillow]\n",
      "   ---------- -----------------------------  32/128 [pillow]\n",
      "  Attempting uninstall: packaging\n",
      "   ---------- -----------------------------  32/128 [pillow]\n",
      "    Found existing installation: packaging 25.0\n",
      "   ---------- -----------------------------  32/128 [pillow]\n",
      "    Uninstalling packaging-25.0:\n",
      "   ---------- -----------------------------  32/128 [pillow]\n",
      "      Successfully uninstalled packaging-25.0\n",
      "   ---------- -----------------------------  32/128 [pillow]\n",
      "   ---------- -----------------------------  33/128 [packaging]\n",
      "   ----------- ----------------------------  36/128 [oauthlib]\n",
      "   ----------- ----------------------------  36/128 [oauthlib]\n",
      "   ----------- ----------------------------  37/128 [numpy]\n",
      "   ----------- ----------------------------  37/128 [numpy]\n",
      "   ----------- ----------------------------  37/128 [numpy]\n",
      "   ----------- ----------------------------  37/128 [numpy]\n",
      "   ----------- ----------------------------  37/128 [numpy]\n",
      "   ----------- ----------------------------  37/128 [numpy]\n",
      "   ----------- ----------------------------  37/128 [numpy]\n",
      "   ----------- ----------------------------  37/128 [numpy]\n",
      "   ----------- ----------------------------  37/128 [numpy]\n",
      "   ----------- ----------------------------  37/128 [numpy]\n",
      "   ----------- ----------------------------  37/128 [numpy]\n",
      "   ----------- ----------------------------  37/128 [numpy]\n",
      "   ----------- ----------------------------  37/128 [numpy]\n",
      "   ----------- ----------------------------  37/128 [numpy]\n",
      "   ----------- ----------------------------  37/128 [numpy]\n",
      "   ----------- ----------------------------  37/128 [numpy]\n",
      "   ----------- ----------------------------  37/128 [numpy]\n",
      "   ----------- ----------------------------  37/128 [numpy]\n",
      "   ----------- ----------------------------  37/128 [numpy]\n",
      "   ----------- ----------------------------  37/128 [numpy]\n",
      "   ----------- ----------------------------  38/128 [narwhals]\n",
      "   ----------- ----------------------------  38/128 [narwhals]\n",
      "   ----------- ----------------------------  38/128 [narwhals]\n",
      "   ----------- ----------------------------  38/128 [narwhals]\n",
      "   ------------ ---------------------------  39/128 [mypy-extensions]\n",
      "   -------------- -------------------------  45/128 [jiter]\n",
      "   -------------- -------------------------  47/128 [idna]\n",
      "   --------------- ------------------------  51/128 [grpcio]\n",
      "   --------------- ------------------------  51/128 [grpcio]\n",
      "   ---------------- -----------------------  52/128 [greenlet]\n",
      "   ---------------- -----------------------  53/128 [fsspec]\n",
      "   ---------------- -----------------------  53/128 [fsspec]\n",
      "   ----------------- ----------------------  57/128 [click]\n",
      "   ------------------ ---------------------  58/128 [charset_normalizer]\n",
      "   ------------------- --------------------  63/128 [backoff]\n",
      "   -------------------- -------------------  66/128 [aiohappyeyeballs]\n",
      "   --------------------- ------------------  68/128 [uvicorn]\n",
      "   ---------------------- -----------------  71/128 [SQLAlchemy]\n",
      "   ---------------------- -----------------  71/128 [SQLAlchemy]\n",
      "   ---------------------- -----------------  71/128 [SQLAlchemy]\n",
      "   ---------------------- -----------------  71/128 [SQLAlchemy]\n",
      "   ---------------------- -----------------  71/128 [SQLAlchemy]\n",
      "   ---------------------- -----------------  71/128 [SQLAlchemy]\n",
      "   ---------------------- -----------------  71/128 [SQLAlchemy]\n",
      "   ---------------------- -----------------  71/128 [SQLAlchemy]\n",
      "   ---------------------- -----------------  71/128 [SQLAlchemy]\n",
      "   ---------------------- -----------------  71/128 [SQLAlchemy]\n",
      "   ---------------------- -----------------  71/128 [SQLAlchemy]\n",
      "   ---------------------- -----------------  73/128 [requests]\n",
      "   ----------------------- ----------------  75/128 [pydantic-core]\n",
      "   ----------------------- ----------------  76/128 [pyasn1-modules]\n",
      "   ----------------------- ----------------  76/128 [pyasn1-modules]\n",
      "   ------------------------ ---------------  77/128 [pandas]\n",
      "   ------------------------ ---------------  77/128 [pandas]\n",
      "   ------------------------ ---------------  77/128 [pandas]\n",
      "   ------------------------ ---------------  77/128 [pandas]\n",
      "   ------------------------ ---------------  77/128 [pandas]\n",
      "   ------------------------ ---------------  77/128 [pandas]\n",
      "   ------------------------ ---------------  77/128 [pandas]\n",
      "   ------------------------ ---------------  77/128 [pandas]\n",
      "   ------------------------ ---------------  77/128 [pandas]\n",
      "   ------------------------ ---------------  77/128 [pandas]\n",
      "   ------------------------ ---------------  77/128 [pandas]\n",
      "   ------------------------ ---------------  77/128 [pandas]\n",
      "   ------------------------ ---------------  77/128 [pandas]\n",
      "   ------------------------ ---------------  77/128 [pandas]\n",
      "   ------------------------ ---------------  77/128 [pandas]\n",
      "   ------------------------ ---------------  77/128 [pandas]\n",
      "   ------------------------ ---------------  77/128 [pandas]\n",
      "   ------------------------ ---------------  77/128 [pandas]\n",
      "   ------------------------ ---------------  77/128 [pandas]\n",
      "   ------------------------ ---------------  77/128 [pandas]\n",
      "   ------------------------ ---------------  77/128 [pandas]\n",
      "   ------------------------ ---------------  77/128 [pandas]\n",
      "   ------------------------ ---------------  77/128 [pandas]\n",
      "   ------------------------ ---------------  77/128 [pandas]\n",
      "   ------------------------ ---------------  77/128 [pandas]\n",
      "   ------------------------ ---------------  77/128 [pandas]\n",
      "   ------------------------ ---------------  77/128 [pandas]\n",
      "   ------------------------ ---------------  77/128 [pandas]\n",
      "   ------------------------ ---------------  77/128 [pandas]\n",
      "   ------------------------ ---------------  77/128 [pandas]\n",
      "   ------------------------ ---------------  77/128 [pandas]\n",
      "   ------------------------ ---------------  77/128 [pandas]\n",
      "   ------------------------ ---------------  77/128 [pandas]\n",
      "   ------------------------ ---------------  77/128 [pandas]\n",
      "   ------------------------ ---------------  77/128 [pandas]\n",
      "   ------------------------ ---------------  77/128 [pandas]\n",
      "   ------------------------ ---------------  77/128 [pandas]\n",
      "   ------------------------ ---------------  77/128 [pandas]\n",
      "   ------------------------ ---------------  77/128 [pandas]\n",
      "   ------------------------ ---------------  77/128 [pandas]\n",
      "   ------------------------ ---------------  77/128 [pandas]\n",
      "   ------------------------ ---------------  77/128 [pandas]\n",
      "   ------------------------ ---------------  77/128 [pandas]\n",
      "   ------------------------ ---------------  77/128 [pandas]\n",
      "   ------------------------ ---------------  77/128 [pandas]\n",
      "   ------------------------ ---------------  77/128 [pandas]\n",
      "   ------------------------ ---------------  77/128 [pandas]\n",
      "   ------------------------ ---------------  77/128 [pandas]\n",
      "   ------------------------ ---------------  77/128 [pandas]\n",
      "   ------------------------ ---------------  77/128 [pandas]\n",
      "   ------------------------ ---------------  77/128 [pandas]\n",
      "   ------------------------ ---------------  77/128 [pandas]\n",
      "   ------------------------ ---------------  79/128 [marshmallow]\n",
      "   ------------------------- --------------  80/128 [markdown-it-py]\n",
      "   ------------------------- --------------  82/128 [jinja2]\n",
      "   ------------------------- --------------  83/128 [importlib-metadata]\n",
      "   -------------------------- -------------  85/128 [httpcore]\n",
      "   -------------------------- -------------  86/128 [googleapis-common-protos]\n",
      "   -------------------------- -------------  86/128 [googleapis-common-protos]\n",
      "   --------------------------- ------------  87/128 [gitdb]\n",
      "   --------------------------- ------------  89/128 [anyio]\n",
      "   ---------------------------- -----------  91/128 [watchfiles]\n",
      "   ----------------------------- ----------  93/128 [rich]\n",
      "   ----------------------------- ----------  93/128 [rich]\n",
      "   ----------------------------- ----------  94/128 [requests-toolbelt]\n",
      "   ----------------------------- ----------  95/128 [requests-oauthlib]\n",
      "   ------------------------------ ---------  96/128 [pydeck]\n",
      "   ------------------------------ ---------  97/128 [pydantic]\n",
      "   ------------------------------ ---------  97/128 [pydantic]\n",
      "   ------------------------------ ---------  97/128 [pydantic]\n",
      "   ------------------------------ ---------  97/128 [pydantic]\n",
      "   ------------------------------ ---------  98/128 [posthog]\n",
      "   ------------------- -----  99/128 [opentelemetry-exporter-otlp-proto-common]\n",
      "   ------------------------------- -------- 101/128 [jsonschema-specifications]\n",
      "   ------------------------------- -------- 102/128 [huggingface-hub]\n",
      "   ------------------------------- -------- 102/128 [huggingface-hub]\n",
      "   ------------------------------- -------- 102/128 [huggingface-hub]\n",
      "   ------------------------------- -------- 102/128 [huggingface-hub]\n",
      "   -------------------------------- ------- 104/128 [google-auth]\n",
      "   -------------------------------- ------- 104/128 [google-auth]\n",
      "   -------------------------------- ------- 105/128 [gitpython]\n",
      "   -------------------------------- ------- 105/128 [gitpython]\n",
      "   --------------------------------- ------ 108/128 [aiohttp]\n",
      "   --------------------------------- ------ 108/128 [aiohttp]\n",
      "   ---------------------------------- ----- 109/128 [typer]\n",
      "   ---------------------------------- ----- 110/128 [tokenizers]\n",
      "   --------------------------- --- 112/128 [opentelemetry-semantic-conventions]\n",
      "   --------------------------- --- 112/128 [opentelemetry-semantic-conventions]\n",
      "   --------------------------- --- 112/128 [opentelemetry-semantic-conventions]\n",
      "   ----------------------------------- ---- 113/128 [openai]\n",
      "   ----------------------------------- ---- 113/128 [openai]\n",
      "   ----------------------------------- ---- 113/128 [openai]\n",
      "   ----------------------------------- ---- 113/128 [openai]\n",
      "   ----------------------------------- ---- 113/128 [openai]\n",
      "   ----------------------------------- ---- 113/128 [openai]\n",
      "   ----------------------------------- ---- 113/128 [openai]\n",
      "   ----------------------------------- ---- 113/128 [openai]\n",
      "   ----------------------------------- ---- 113/128 [openai]\n",
      "   ----------------------------------- ---- 113/128 [openai]\n",
      "   ----------------------------------- ---- 113/128 [openai]\n",
      "   ----------------------------------- ---- 113/128 [openai]\n",
      "   ----------------------------------- ---- 113/128 [openai]\n",
      "   ----------------------------------- ---- 113/128 [openai]\n",
      "   ----------------------------------- ---- 113/128 [openai]\n",
      "   ----------------------------------- ---- 114/128 [onnxruntime]\n",
      "   ----------------------------------- ---- 114/128 [onnxruntime]\n",
      "   ----------------------------------- ---- 114/128 [onnxruntime]\n",
      "   ----------------------------------- ---- 114/128 [onnxruntime]\n",
      "   ----------------------------------- ---- 114/128 [onnxruntime]\n",
      "   ----------------------------------- ---- 114/128 [onnxruntime]\n",
      "   ----------------------------------- ---- 114/128 [onnxruntime]\n",
      "   ----------------------------------- ---- 114/128 [onnxruntime]\n",
      "   ----------------------------------- ---- 114/128 [onnxruntime]\n",
      "   ----------------------------------- ---- 114/128 [onnxruntime]\n",
      "   ----------------------------------- ---- 115/128 [langsmith]\n",
      "   ------------------------------------ --- 116/128 [kubernetes]\n",
      "   ------------------------------------ --- 116/128 [kubernetes]\n",
      "   ------------------------------------ --- 116/128 [kubernetes]\n",
      "   ------------------------------------ --- 116/128 [kubernetes]\n",
      "   ------------------------------------ --- 116/128 [kubernetes]\n",
      "   ------------------------------------ --- 116/128 [kubernetes]\n",
      "   ------------------------------------ --- 116/128 [kubernetes]\n",
      "   ------------------------------------ --- 116/128 [kubernetes]\n",
      "   ------------------------------------ --- 116/128 [kubernetes]\n",
      "   ------------------------------------ --- 116/128 [kubernetes]\n",
      "   ------------------------------------ --- 116/128 [kubernetes]\n",
      "   ------------------------------------ --- 116/128 [kubernetes]\n",
      "   ------------------------------------ --- 116/128 [kubernetes]\n",
      "   ------------------------------------ --- 116/128 [kubernetes]\n",
      "   ------------------------------------ --- 116/128 [kubernetes]\n",
      "   ------------------------------------ --- 116/128 [kubernetes]\n",
      "   ------------------------------------ --- 116/128 [kubernetes]\n",
      "   ------------------------------------ --- 116/128 [kubernetes]\n",
      "   ------------------------------------ --- 116/128 [kubernetes]\n",
      "   ------------------------------------ --- 116/128 [kubernetes]\n",
      "   ------------------------------------ --- 116/128 [kubernetes]\n",
      "   ------------------------------------ --- 116/128 [kubernetes]\n",
      "   ------------------------------------ --- 117/128 [jsonschema]\n",
      "   ------------------------------------ --- 118/128 [opentelemetry-sdk]\n",
      "   ------------------------------------- -- 119/128 [langchain-core]\n",
      "   ------------------------------------- -- 119/128 [langchain-core]\n",
      "   ------------------------------------- -- 119/128 [langchain-core]\n",
      "   ------------------------------------- -- 119/128 [langchain-core]\n",
      "   ------------------------------------- -- 119/128 [langchain-core]\n",
      "   ------------------------------------- -- 120/128 [altair]\n",
      "   ------------------------------------- -- 120/128 [altair]\n",
      "   ------------------------------------- -- 120/128 [altair]\n",
      "   ------------------------------------- -- 121/128 [streamlit]\n",
      "   ------------------------------------- -- 121/128 [streamlit]\n",
      "   ------------------------------------- -- 121/128 [streamlit]\n",
      "   ------------------------------------- -- 121/128 [streamlit]\n",
      "   ------------------------------------- -- 121/128 [streamlit]\n",
      "   ------------------------------------- -- 121/128 [streamlit]\n",
      "   ------------------------------------- -- 121/128 [streamlit]\n",
      "   ------------------------------------- -- 121/128 [streamlit]\n",
      "   ------------------------------------- -- 121/128 [streamlit]\n",
      "   ------------------------- - 122/128 [opentelemetry-exporter-otlp-proto-grpc]\n",
      "   ---------------------------------------  125/128 [langchain]\n",
      "   ---------------------------------------  125/128 [langchain]\n",
      "   ---------------------------------------  125/128 [langchain]\n",
      "   ---------------------------------------  125/128 [langchain]\n",
      "   ---------------------------------------  125/128 [langchain]\n",
      "   ---------------------------------------  125/128 [langchain]\n",
      "   ---------------------------------------  125/128 [langchain]\n",
      "   ---------------------------------------  125/128 [langchain]\n",
      "   ---------------------------------------  125/128 [langchain]\n",
      "   ---------------------------------------  125/128 [langchain]\n",
      "   ---------------------------------------  125/128 [langchain]\n",
      "   ---------------------------------------  125/128 [langchain]\n",
      "   ---------------------------------------  125/128 [langchain]\n",
      "   ---------------------------------------  125/128 [langchain]\n",
      "   ---------------------------------------  125/128 [langchain]\n",
      "   ---------------------------------------  125/128 [langchain]\n",
      "   ---------------------------------------  125/128 [langchain]\n",
      "   ---------------------------------------  125/128 [langchain]\n",
      "   ---------------------------------------  125/128 [langchain]\n",
      "   ---------------------------------------  125/128 [langchain]\n",
      "   ---------------------------------------  125/128 [langchain]\n",
      "   ---------------------------------------  125/128 [langchain]\n",
      "   ---------------------------------------  125/128 [langchain]\n",
      "   ---------------------------------------  125/128 [langchain]\n",
      "   ---------------------------------------  126/128 [chromadb]\n",
      "   ---------------------------------------  126/128 [chromadb]\n",
      "   ---------------------------------------  126/128 [chromadb]\n",
      "   ---------------------------------------  126/128 [chromadb]\n",
      "   ---------------------------------------  126/128 [chromadb]\n",
      "   ---------------------------------------  126/128 [chromadb]\n",
      "   ---------------------------------------  126/128 [chromadb]\n",
      "   ---------------------------------------  127/128 [langchain-community]\n",
      "   ---------------------------------------  127/128 [langchain-community]\n",
      "   ---------------------------------------  127/128 [langchain-community]\n",
      "   ---------------------------------------  127/128 [langchain-community]\n",
      "   ---------------------------------------  127/128 [langchain-community]\n",
      "   ---------------------------------------  127/128 [langchain-community]\n",
      "   ---------------------------------------  127/128 [langchain-community]\n",
      "   ---------------------------------------  127/128 [langchain-community]\n",
      "   ---------------------------------------  127/128 [langchain-community]\n",
      "   ---------------------------------------  127/128 [langchain-community]\n",
      "   ---------------------------------------  127/128 [langchain-community]\n",
      "   ---------------------------------------  127/128 [langchain-community]\n",
      "   ---------------------------------------  127/128 [langchain-community]\n",
      "   ---------------------------------------  127/128 [langchain-community]\n",
      "   ---------------------------------------  127/128 [langchain-community]\n",
      "   ---------------------------------------  127/128 [langchain-community]\n",
      "   ---------------------------------------  127/128 [langchain-community]\n",
      "   ---------------------------------------  127/128 [langchain-community]\n",
      "   ---------------------------------------  127/128 [langchain-community]\n",
      "   ---------------------------------------  127/128 [langchain-community]\n",
      "   ---------------------------------------  127/128 [langchain-community]\n",
      "   ---------------------------------------  127/128 [langchain-community]\n",
      "   ---------------------------------------  127/128 [langchain-community]\n",
      "   ---------------------------------------  127/128 [langchain-community]\n",
      "   ---------------------------------------  127/128 [langchain-community]\n",
      "   ---------------------------------------  127/128 [langchain-community]\n",
      "   ---------------------------------------  127/128 [langchain-community]\n",
      "   ---------------------------------------  127/128 [langchain-community]\n",
      "   ---------------------------------------  127/128 [langchain-community]\n",
      "   ---------------------------------------  127/128 [langchain-community]\n",
      "   ---------------------------------------- 128/128 [langchain-community]\n",
      "\n",
      "Successfully installed MarkupSafe-3.0.2 PyYAML-6.0.2 SQLAlchemy-2.0.41 aiohappyeyeballs-2.6.1 aiohttp-3.12.14 aiosignal-1.4.0 altair-5.5.0 annotated-types-0.7.0 anyio-4.9.0 attrs-25.3.0 backoff-2.2.1 bcrypt-4.3.0 blinker-1.9.0 build-1.2.2.post1 cachetools-5.5.2 certifi-2025.7.9 charset_normalizer-3.4.2 chromadb-1.0.15 click-8.2.1 coloredlogs-15.0.1 dataclasses-json-0.6.7 distro-1.9.0 durationpy-0.10 filelock-3.18.0 flatbuffers-25.2.10 frozenlist-1.7.0 fsspec-2025.5.1 gitdb-4.0.12 gitpython-3.1.44 google-auth-2.40.3 googleapis-common-protos-1.70.0 greenlet-3.2.3 grpcio-1.73.1 h11-0.16.0 httpcore-1.0.9 httptools-0.6.4 httpx-0.28.1 httpx-sse-0.4.1 huggingface-hub-0.33.4 humanfriendly-10.0 idna-3.10 importlib-metadata-8.7.0 importlib-resources-6.5.2 jinja2-3.1.6 jiter-0.10.0 jsonpatch-1.33 jsonpointer-3.0.0 jsonschema-4.24.0 jsonschema-specifications-2025.4.1 kubernetes-33.1.0 langchain-0.3.26 langchain-community-0.3.27 langchain-core-0.3.68 langchain-openai-0.3.27 langchain-text-splitters-0.3.8 langsmith-0.4.5 markdown-it-py-3.0.0 marshmallow-3.26.1 mdurl-0.1.2 mmh3-5.1.0 mpmath-1.3.0 multidict-6.6.3 mypy-extensions-1.1.0 narwhals-1.46.0 numpy-2.3.1 oauthlib-3.3.1 onnxruntime-1.22.1 openai-1.95.1 opentelemetry-api-1.35.0 opentelemetry-exporter-otlp-proto-common-1.35.0 opentelemetry-exporter-otlp-proto-grpc-1.35.0 opentelemetry-proto-1.35.0 opentelemetry-sdk-1.35.0 opentelemetry-semantic-conventions-0.56b0 orjson-3.10.18 overrides-7.7.0 packaging-24.2 pandas-2.3.1 pillow-11.3.0 posthog-5.4.0 propcache-0.3.2 protobuf-6.31.1 pyarrow-20.0.0 pyasn1-0.6.1 pyasn1-modules-0.4.2 pybase64-1.4.1 pydantic-2.11.7 pydantic-core-2.33.2 pydantic-settings-2.10.1 pydeck-0.9.1 pypdf-5.7.0 pypika-0.48.9 pyproject_hooks-1.2.0 pyreadline3-3.5.4 python-dotenv-1.1.1 pytz-2025.2 referencing-0.36.2 regex-2024.11.6 requests-2.32.4 requests-oauthlib-2.0.0 requests-toolbelt-1.0.0 rich-14.0.0 rpds-py-0.26.0 rsa-4.9.1 shellingham-1.5.4 smmap-5.0.2 sniffio-1.3.1 streamlit-1.46.1 sympy-1.14.0 tenacity-9.1.2 tiktoken-0.9.0 tokenizers-0.21.2 toml-0.10.2 tqdm-4.67.1 typer-0.16.0 typing-extensions-4.14.1 typing-inspect-0.9.0 typing-inspection-0.4.1 tzdata-2025.2 urllib3-2.5.0 uvicorn-0.35.0 watchdog-6.0.0 watchfiles-1.1.0 websocket-client-1.8.0 websockets-15.0.1 yarl-1.20.1 zipp-3.23.0 zstandard-0.23.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install langchain langchain-community pypdf langchain-openai chromadb pandas streamlit python-dotenv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "234ad015",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\VishuManjhi\\Desktop\\Evy\\AI Data Extracter\\venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py:3699: LangChainDeprecationWarning: As of langchain-core 0.3.0, LangChain uses pydantic v2 internally. The langchain_core.pydantic_v1 module was a compatibility shim for pydantic v1, and should no longer be used. Please update the code to import from Pydantic directly.\n",
      "\n",
      "For example, replace imports like: `from langchain_core.pydantic_v1 import BaseModel`\n",
      "with: `from pydantic import BaseModel`\n",
      "or the v1 compatibility namespace if you are working in a code base that has not been fully upgraded to pydantic 2 yet. \tfrom pydantic.v1 import BaseModel\n",
      "\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    }
   ],
   "source": [
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "\n",
    "import os\n",
    "import tempfile\n",
    "import uuid\n",
    "import pandas as pd\n",
    "import re\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d3264e6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "064aad56",
   "metadata": {},
   "outputs": [],
   "source": [
    "gemini_api_key = os.getenv(\"GEMINI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "980e7087",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'AIzaSyDgcB4frVwNLcl0r_HOebtP4VzvovkW9O4'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getenv(\"GEMINI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "665650e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain-google-genai in c:\\users\\vishumanjhi\\desktop\\evy\\ai data extracter\\venv\\lib\\site-packages (2.0.10)\n",
      "Requirement already satisfied: google-generativeai in c:\\users\\vishumanjhi\\desktop\\evy\\ai data extracter\\venv\\lib\\site-packages (0.8.5)\n",
      "Requirement already satisfied: filetype<2.0.0,>=1.2.0 in c:\\users\\vishumanjhi\\desktop\\evy\\ai data extracter\\venv\\lib\\site-packages (from langchain-google-genai) (1.2.0)\n",
      "Requirement already satisfied: langchain-core<0.4.0,>=0.3.37 in c:\\users\\vishumanjhi\\desktop\\evy\\ai data extracter\\venv\\lib\\site-packages (from langchain-google-genai) (0.3.68)\n",
      "Requirement already satisfied: pydantic<3,>=2 in c:\\users\\vishumanjhi\\desktop\\evy\\ai data extracter\\venv\\lib\\site-packages (from langchain-google-genai) (2.11.7)\n",
      "Requirement already satisfied: google-ai-generativelanguage==0.6.15 in c:\\users\\vishumanjhi\\desktop\\evy\\ai data extracter\\venv\\lib\\site-packages (from google-generativeai) (0.6.15)\n",
      "Requirement already satisfied: google-api-core in c:\\users\\vishumanjhi\\desktop\\evy\\ai data extracter\\venv\\lib\\site-packages (from google-generativeai) (2.25.1)\n",
      "Requirement already satisfied: google-api-python-client in c:\\users\\vishumanjhi\\desktop\\evy\\ai data extracter\\venv\\lib\\site-packages (from google-generativeai) (2.176.0)\n",
      "Requirement already satisfied: google-auth>=2.15.0 in c:\\users\\vishumanjhi\\desktop\\evy\\ai data extracter\\venv\\lib\\site-packages (from google-generativeai) (2.40.3)\n",
      "Requirement already satisfied: protobuf in c:\\users\\vishumanjhi\\desktop\\evy\\ai data extracter\\venv\\lib\\site-packages (from google-generativeai) (5.29.5)\n",
      "Requirement already satisfied: tqdm in c:\\users\\vishumanjhi\\desktop\\evy\\ai data extracter\\venv\\lib\\site-packages (from google-generativeai) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\vishumanjhi\\desktop\\evy\\ai data extracter\\venv\\lib\\site-packages (from google-generativeai) (4.14.1)\n",
      "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in c:\\users\\vishumanjhi\\desktop\\evy\\ai data extracter\\venv\\lib\\site-packages (from google-ai-generativelanguage==0.6.15->google-generativeai) (1.26.1)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in c:\\users\\vishumanjhi\\desktop\\evy\\ai data extracter\\venv\\lib\\site-packages (from google-api-core->google-generativeai) (1.70.0)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.18.0 in c:\\users\\vishumanjhi\\desktop\\evy\\ai data extracter\\venv\\lib\\site-packages (from google-api-core->google-generativeai) (2.32.4)\n",
      "Requirement already satisfied: grpcio<2.0.0,>=1.33.2 in c:\\users\\vishumanjhi\\desktop\\evy\\ai data extracter\\venv\\lib\\site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.73.1)\n",
      "Requirement already satisfied: grpcio-status<2.0.0,>=1.33.2 in c:\\users\\vishumanjhi\\desktop\\evy\\ai data extracter\\venv\\lib\\site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.71.2)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\vishumanjhi\\desktop\\evy\\ai data extracter\\venv\\lib\\site-packages (from google-auth>=2.15.0->google-generativeai) (5.5.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\vishumanjhi\\desktop\\evy\\ai data extracter\\venv\\lib\\site-packages (from google-auth>=2.15.0->google-generativeai) (0.4.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\vishumanjhi\\desktop\\evy\\ai data extracter\\venv\\lib\\site-packages (from google-auth>=2.15.0->google-generativeai) (4.9.1)\n",
      "Requirement already satisfied: langsmith>=0.3.45 in c:\\users\\vishumanjhi\\desktop\\evy\\ai data extracter\\venv\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.37->langchain-google-genai) (0.4.5)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in c:\\users\\vishumanjhi\\desktop\\evy\\ai data extracter\\venv\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.37->langchain-google-genai) (9.1.2)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\vishumanjhi\\desktop\\evy\\ai data extracter\\venv\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.37->langchain-google-genai) (1.33)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\vishumanjhi\\desktop\\evy\\ai data extracter\\venv\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.37->langchain-google-genai) (6.0.2)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in c:\\users\\vishumanjhi\\desktop\\evy\\ai data extracter\\venv\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.37->langchain-google-genai) (24.2)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\vishumanjhi\\desktop\\evy\\ai data extracter\\venv\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.37->langchain-google-genai) (3.0.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\vishumanjhi\\desktop\\evy\\ai data extracter\\venv\\lib\\site-packages (from pydantic<3,>=2->langchain-google-genai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in c:\\users\\vishumanjhi\\desktop\\evy\\ai data extracter\\venv\\lib\\site-packages (from pydantic<3,>=2->langchain-google-genai) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\users\\vishumanjhi\\desktop\\evy\\ai data extracter\\venv\\lib\\site-packages (from pydantic<3,>=2->langchain-google-genai) (0.4.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\vishumanjhi\\desktop\\evy\\ai data extracter\\venv\\lib\\site-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\vishumanjhi\\desktop\\evy\\ai data extracter\\venv\\lib\\site-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\vishumanjhi\\desktop\\evy\\ai data extracter\\venv\\lib\\site-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\vishumanjhi\\desktop\\evy\\ai data extracter\\venv\\lib\\site-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (2025.7.9)\n",
      "Requirement already satisfied: pyasn1>=0.1.3 in c:\\users\\vishumanjhi\\desktop\\evy\\ai data extracter\\venv\\lib\\site-packages (from rsa<5,>=3.1.4->google-auth>=2.15.0->google-generativeai) (0.6.1)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\vishumanjhi\\desktop\\evy\\ai data extracter\\venv\\lib\\site-packages (from langsmith>=0.3.45->langchain-core<0.4.0,>=0.3.37->langchain-google-genai) (0.28.1)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in c:\\users\\vishumanjhi\\desktop\\evy\\ai data extracter\\venv\\lib\\site-packages (from langsmith>=0.3.45->langchain-core<0.4.0,>=0.3.37->langchain-google-genai) (3.10.18)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in c:\\users\\vishumanjhi\\desktop\\evy\\ai data extracter\\venv\\lib\\site-packages (from langsmith>=0.3.45->langchain-core<0.4.0,>=0.3.37->langchain-google-genai) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in c:\\users\\vishumanjhi\\desktop\\evy\\ai data extracter\\venv\\lib\\site-packages (from langsmith>=0.3.45->langchain-core<0.4.0,>=0.3.37->langchain-google-genai) (0.23.0)\n",
      "Requirement already satisfied: anyio in c:\\users\\vishumanjhi\\desktop\\evy\\ai data extracter\\venv\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith>=0.3.45->langchain-core<0.4.0,>=0.3.37->langchain-google-genai) (4.9.0)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\vishumanjhi\\desktop\\evy\\ai data extracter\\venv\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith>=0.3.45->langchain-core<0.4.0,>=0.3.37->langchain-google-genai) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\users\\vishumanjhi\\desktop\\evy\\ai data extracter\\venv\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith>=0.3.45->langchain-core<0.4.0,>=0.3.37->langchain-google-genai) (0.16.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\vishumanjhi\\desktop\\evy\\ai data extracter\\venv\\lib\\site-packages (from anyio->httpx<1,>=0.23.0->langsmith>=0.3.45->langchain-core<0.4.0,>=0.3.37->langchain-google-genai) (1.3.1)\n",
      "Requirement already satisfied: httplib2<1.0.0,>=0.19.0 in c:\\users\\vishumanjhi\\desktop\\evy\\ai data extracter\\venv\\lib\\site-packages (from google-api-python-client->google-generativeai) (0.22.0)\n",
      "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in c:\\users\\vishumanjhi\\desktop\\evy\\ai data extracter\\venv\\lib\\site-packages (from google-api-python-client->google-generativeai) (0.2.0)\n",
      "Requirement already satisfied: uritemplate<5,>=3.0.1 in c:\\users\\vishumanjhi\\desktop\\evy\\ai data extracter\\venv\\lib\\site-packages (from google-api-python-client->google-generativeai) (4.2.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in c:\\users\\vishumanjhi\\desktop\\evy\\ai data extracter\\venv\\lib\\site-packages (from httplib2<1.0.0,>=0.19.0->google-api-python-client->google-generativeai) (3.2.3)\n",
      "Requirement already satisfied: colorama in c:\\users\\vishumanjhi\\desktop\\evy\\ai data extracter\\venv\\lib\\site-packages (from tqdm->google-generativeai) (0.4.6)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install langchain-google-genai google-generativeai\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fdc92f67",
   "metadata": {},
   "outputs": [],
   "source": [
    "##DEFINE OUR LLM \n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "import os\n",
    "\n",
    "llm = ChatGoogleGenerativeAI(\n",
    "    model=\"gemini-1.5-flash\",\n",
    "    google_api_key=\"AIzaSyDgcB4frVwNLcl0r_HOebtP4VzvovkW9O4\"  \n",
    ")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "096d100c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "946b212f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Why was the cat sitting on the computer?  \\n\\nTo keep an eye on the mouse!', additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'safety_ratings': []}, id='run--f79fec8c-d4f6-499a-a417-7b4d01c8b284-0', usage_metadata={'input_tokens': 7, 'output_tokens': 20, 'total_tokens': 27, 'input_token_details': {'cache_read': 0}})"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm = ChatGoogleGenerativeAI(model=\"gemini-1.5-flash\", google_api_key=os.getenv(\"GEMINI_API_KEY\"))\n",
    "llm.invoke(\"Tell me a joke about cats.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "583ad909",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'producer': 'dvips + GPL Ghostscript 9.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2016-01-27T12:06:33-05:00', 'moddate': '2016-01-27T12:06:33-05:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': 'data\\\\Cognitive.pdf', 'total_pages': 15, 'page': 0, 'page_label': '99'}, page_content='Judgment and Decision Making, V ol. 11, No. 1, January 2016, pp. 99 –113\\nInvestigating an alternate form of the cognitive reﬂection test\\nKeela S. Thomson ∗ Daniel M. Oppenheimer ∗\\nAbstract\\nMuch research in cognitive psychology has focused on the tendency to conserve limited cognitive resources. The CR T is\\nthe predominant measure of such miserly information processing, and also predicts a number of frequently studied decision-\\nmaking traits (such as belief bias and need for cognition). However, man y subjects from common subject populations have\\nalready been exposed to the questions, which might add considerable no ise to data. Moreover, the CR T has been shown\\nto be confounded with numeracy . T o increase the pool of available ques tions and to try to address numeracy confounds, we\\ndeveloped and tested the CR T -2. CR T -2 questions appear to rely less on n umeracy than the original CR T but appear to measure\\nclosely related constructs in other respects. Crucially , substantially fewer subjects from Amazon’s Mechanical Turk have been\\npreviously exposed to CR T -2 questions. Though our primary purpose was investigating the CR T -2, we also found that belief\\nbias questions appear suitable as an additional source of new items. Implic ations and remaining measurement challenges are\\ndiscussed. Keywords: cognitive reﬂection, CR T .\\n1 Introduction\\nThe CR T is one of the most widely used instruments in\\nheuristics-and-biases research. It is designed to measure a\\nperson’s propensity to override an intuitive, but incorrec t,\\nresponse with a more analytical correct response (Freder-\\nick, 2005). Miserly processing (the tendency not to overrid e\\nthe intuitive response) as measured by the CR T is frequently\\nassociated with non-normative responses across a number of\\ncognitive domains.\\nCR T performance has been linked with an extensive list\\nof rational thinking tasks. For example, Frederick (2005)\\nfound relationships between CR T scores and time prefer-\\nence (preference for immediate versus delayed outcomes),\\nrisk preference (preference for risky versus certain out-\\ncomes), and need for cognition (a tendency to enjoy effortfu l\\nthinking). CR T scores are also related to belief bias (the te n-\\ndency to be inﬂuenced by the believability of the conclusion\\nwhen evaluating the validity of logical arguments) and de-\\nnominator neglect (the tendency to focus on the number of a\\nparticular kind of outcome, the numerator, without consid-\\nering the total number of possible events, the denominator;\\nT oplak, W est & Stanovich, 2014a).\\nIn addition, CR T scores have been linked with: SA T\\nscores (Frederick, 2005; Obrecht, Chapman & Gelman,\\n2009), frequency of choices consistent with expected value\\n(Cokely & Kelley , 2009; Oechssler, Roider & Schmitz,\\n2009), the likelihood of committing the conjunction fal-\\nlacy (Oechssle et al., 2009), probability updating, base ra te\\nneglect, under- and over-conﬁdence (Hoppe & Kusterer,\\nCopyright: © 2016. The authors license this article under th e terms of\\nthe Creative Commons Attribution 3.0 License.\\n∗ University of California, Los Angeles\\n2011), regression to the mean, errors in Bayesian reasoning ,\\nframing effects (T oplak, W est & Stanovich, 2011), W ason\\nselection task performance, (T oplak et al., 2014a), using a nd\\nendorsing maximizing strategies on probabilistic predict ion\\ntasks (Koehler & James, 2010), and a reduction in the de-\\ngree to which people underweight sample size and standard\\ndeviation in making pairwise comparisons (Obrecht, Chap-\\nman & Gelman, 2007). CR T scores have also been asso-\\nciated with utilitarian moral judgments (Paxton, Ungar &\\nGreene, 2012; Royzman, Landy & Leeman, 2014; Baron,\\nScott, Fincher & Metz, 2015).\\nIn fact, T oplak et al. (2011) found that the CR T better pre-\\ndicted performance on a composite of 15 separate rational-\\nthinking tasks than either intelligence measures or measur es\\nof executive functioning. They suggest that a major strengt h\\nof the CR T is that it is a direct measure of miserly processing\\nas opposed to a self-report measure (as is the case for most\\nother measures of thinking dispositions), and that the CR T\\ngoes beyond measures of cognitive ability by examining the\\ndepth of processing that is actually used.\\nUnsurprisingly , there is a high degree of interest in study-\\ning cognitive reﬂection using the CR T . However, the CR T\\nis so widely used that subject pools may be polluted, so\\nthat many subjects are already familiar with the questions\\n(T oplak et al., 2014a; Baron et al., 2015; Chandler, Mueller\\n& Paolacci, 2014). Frederick’s original publication of the\\nCR T has over 1,300 citations on Google Scholar. The\\niconic “bat and ball” question has appeared in popular non-\\nﬁction books such as Kahneman’s Thinking, F ast and Slow\\n(Kahneman, 2011), and mainstream media outlets like The\\nNew Y ork Times (Postrel, 2006) and Business Insider (Lu-\\nbin, 2012), which means that many potential subjects have\\nbeen exposed to CR T questions. Moreover, the CR T is fre-\\n99'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript 9.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2016-01-27T12:06:33-05:00', 'moddate': '2016-01-27T12:06:33-05:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': 'data\\\\Cognitive.pdf', 'total_pages': 15, 'page': 1, 'page_label': '100'}, page_content='Judgment and Decision Making, V ol. 11, No. 1, January 2016 Alternate form of the CR T 100\\nquently taught in introductory psychology and cognitive sc i-\\nence courses, which are the source of many university sub-\\nject pools.\\nW e should be particularly concerned with samples drawn\\nfrom Amazon’s Mechanical Turk (MTurk). Though a cheap\\nand convenient method of collecting data, MTurk presents\\nits own unique challenges with respect to subject pool con-\\ntamination. W orkers on MTurk may remain subjects for\\nlonger than the typical undergraduates from a university\\nsubject pool and often complete a higher volume of stud-\\nies, thus gaining more opportunity for exposure to com-\\nmon research paradigms. In one study’s sample, the aver-\\nage MTurk worker had completed a staggering 1,500 MTurk\\njobs, of which 300 were academic studies (Rand et al.,\\n2014). Another recent analysis found that it takes about\\nseven months for half of the pool of workers to be replaced\\n(Stewart et al., 2015).\\nThe issue of prior exposure may be further exacerbated\\nby the fact that the pool of available workers is smaller\\nthan might be assumed. A recent analysis using capture-\\nrecapture analysis found that the average lab samples from\\na pool of about 7,300 MTurk workers (so a lab’s reach in\\npractice is much smaller than the population of 50,000 ad-\\nvertised by Amazon; Stewart et al., 2015). Further, a small\\nnumber of extremely active workers within this pool (some-\\ntimes referred to as “professional” subjects) are responsi -\\nble for large proportion of study responses (Chandler et\\nal., 2014; Berinsky , Huber & Lenz, 2012). Chandler et\\nal. (2014) pooled MTurk data from several collaborating\\nlabs and found that 41% of the responses were generated by\\nonly 10% of respondents. Across seven studies conducted\\nby Berinsky and colleagues (2012) with over 1,500 unique\\nsubjects, 30% of subjects had participated in more than one\\nstudy (the mean number of studies completed per subject\\nwas 1.7). Similarly , Stewart et al. (2015) ﬁnd high rates\\nof repeated participation within laboratories. Further, t he\\nmajority of workers “follow” favorite requesters, and this\\npractice is more common among the most proliﬁc workers\\n(Chandler et al., 2014).\\nAlthough we are not aware of prior work that has di-\\nrectly tested the extent of prior exposure, there is evidenc e\\nthat the high participation rate among MTurk workers ac-\\ntually does translate to contamination. One study of 300\\nworkers found that a concerningly high proportion of work-\\ners reported previous exposure to several common research\\nparadigms (Chandler et al., 2014). The two most commonly\\nencountered paradigms (the prisoner’s dilemma and the ul-\\ntimatum game) had been seen previously by more than half\\nof the subjects. Prior exposure can substantially affect st udy\\nresults: using non-naïve subjects can reduce effect sizes\\n(Chandler, Paolacci, Peer, Mueller & Ratliff, 2015), and\\npractice effects have increased scores on cognitive measur es\\nsuch as the Wisconsin card sorting task (Basso, Bornstein &\\nLang, 1999). In fact, Chandler et al. (2014) selected the CR T\\nto study practice effects since it is well-known that the CR T\\nis commonly used on MTurk. Although they did not directly\\nmeasure the proportion of respondents who had been previ-\\nously exposed to the CR T , they found that CR T scores could\\nbe predicted by the number of studies that workers had pre-\\nviously completed.\\nIn order to assess the extent to which prior exposure ac-\\ntually poses a problem for studies using the CR T , we ad-\\nministered the CR T to 200 subjects on MTurk along with a\\nrational thinking battery including a belief bias measure, a\\nnumeracy scale, a denominator neglect measure, and the 18\\nquestion need for cognition scale. 1 In our sample, 72% of\\nsubjects reported prior exposure to at least one of the CR T\\nquestions. Subjects who reported prior exposure answered\\nsigniﬁcantly more CR T questions correctly (M = 1.90, N =\\n144) than those who did not (M = 1.29, N = 56), t(198)\\n= 3.264, p = .001. Thus, in our sample, prior exposure\\ndid inﬂate CR T scores, suggesting that scores should not\\nbe compared across subjects who have and those who have\\nnot been previously exposed. W e present further evidence\\non this point in the Discussion section.\\nIn order to help deal with over-exposure to the CR T we\\ndeveloped and tested a group of new CR T questions. Im-\\nportantly , as mentioned above, Chandler et al. (2014) found\\nthat CR T performance was positively correlated with MTurk\\nexperience (suggesting practice effects), but this was not the\\ncase for new but conceptually equivalent CR T items.\\nOther researchers have also noticed the problem and\\nhave begun writing new questions. T oplak and colleagues\\n(2014a) tested four new CR T questions, examining their re-\\nlationship with a number of dispositional thinking measure s\\nsuch as framing problems, denominator neglect, and belief\\nbias syllogistic reasoning. Baron et al. (2015) also used se v-\\neral new types of CR T -like questions, including arithmetic\\nquestions parallel in structure to Frederick’s original it ems,\\nbelief bias questions, and logical syllogism reasoning que s-\\ntions.2 Additionally , when Frederick originally created the\\nCR T , he wrote an eight-item version, and has more recently\\ndeveloped a ten-item version as well (S. Frederick, per-\\nsonal communication, October 23, 2015). Primi, Morsanyi,\\nChiesi, Donati and Hamilton (2015) also tested several new\\nCR T items (including some of Frederick’s new items) to cre-\\nate the CR T -Long, which was developed largely to address\\nﬂoor effects in populations including developmental sam-\\nples. Finally , Ackerman and Zalmanov (2012) developed\\na list of 12 misleading questions, including the three from\\nthe original CR T and several tricky math problems adapted\\nfrom the GMA T . The authors did not speciﬁcally investigate\\n1 These same measures are used and described in further detail in Study\\n2. See Appendix A for further details on the study procedure.\\n2 Many of Baron et al. ’s questions were drawn from the work of ot hers,\\nincluding Markovits and Nantel (1989), De Neys and Franssen s (2009),\\nJohnson-Laird and Bara (1984), Finucane and Gullion (2010) , T oplak and\\nStanovich (2002), Bockenhölt (2012), and Levesque (1986, 1 989).'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript 9.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2016-01-27T12:06:33-05:00', 'moddate': '2016-01-27T12:06:33-05:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': 'data\\\\Cognitive.pdf', 'total_pages': 15, 'page': 2, 'page_label': '101'}, page_content='Judgment and Decision Making, V ol. 11, No. 1, January 2016 Alternate form of the CR T 101\\nwhether the problems might be used to create a new mea-\\nsure of cognitive reﬂection, but did note that they were the\\nsame type of problem typically used to study dual process\\ntheories. Their problem list was not printed in the article,\\nbut it was published in full in Ackerman (2014).\\nEven aside from concerns about prior exposure, addi-\\ntional questions may be helpful in addressing other issues\\nwith the CR T . First, researchers ﬁnd ﬂoor effects with many\\npopulations (Frederick, 2005; T oplak et al., 2014a; Ack-\\nerman & Zalmanov , 2012), which can limit the range of\\npopulations that can be sampled and the generalizability of\\nthe ﬁndings. For example, Frederick (2005) found average\\nscores above 1.5 (50% correct) only among elite university\\nstudents.\\nFurther, correctly answering the CR T questions requires\\nnumerical ability . Numerous studies have found correlatio ns\\nbetween the CR T and numeracy , ranging from 0.31 to 0.51\\n(Campitelli & Gerrans, 2014; Cokely & Kelley , 2009; Lib-\\nerali, Reyna, Furlan, Stein & Pardo, 2012; Finucane & Gul-\\nlion, 2010; W eller et al., 2013; W elsh, Burns & Delfrabbo,\\n2013). It is possible that this numeracy confound causes\\nor contributes to observed gender differences such that men\\ntypically score higher than women on the CR T (e.g., Freder-\\nick, 2005). A large body of research suggests that the CR T\\nmeasures both cognitive reﬂection and numeracy (Böcken-\\nholt, 2012; Campitelli & Gerrans, 2014; Sinayev & Peters,\\n2015; Del Missier, Mäntylä & Bruine de Bruin, 2012; W elsh\\net al., 2013, but see Liberali et al. 2012 for an alternative\\nperspective).\\nSinayev and Peters (2015) explain nicely how three-\\ncategory coding can be used to begin to tease apart the con-\\ntributions of both cognitive reﬂection and numeracy to the\\nCR T . According to the cognitive reﬂection hypothesis, ﬁrst\\nthe intuitive answer comes to mind and is either rejected or\\nnot depending on the level of cognitive reﬂection. If the in-\\ntuitive response is rejected, the subsequent response may b e\\ncalculated correctly or incorrectly depending on numeracy\\nskills. Thus, whereas traditionally CR T answers are scored\\nas either correct or incorrect, cognitive reﬂection can be s ep-\\narated from numeracy by using three response categories:\\nintuitive errors, non-intuitive errors, and non-intuitiv e cor-\\nrect responses. Here, cognitive reﬂection is deﬁned as the\\npropensity to give non-intuitive responses, and numeracy i s\\ndeﬁned as the ability to calculate the correct answer given\\nthat the intuitive answer was rejected (Sinayev & Peters,\\n2015).\\nAs it has been demonstrated previously that numerical\\nability is related to rational thinking measures (Peters et al.,\\n2006; Peters et al., 2009; see Reyna, Nelason, Han & Dieck-\\nman, 2009; Peters, 2012, for reviews), Sinayev and Peters\\n(2015) further investigated whether it is the numerical abi l-\\nity or the cognitive reﬂection component of the CR T that\\npredicts performance on rational thinking measures. They\\nfound that, although the CR T measures both cognitive re-\\nﬂection and numeracy , numeracy accounted for the CR T’s\\nability to predict normative decision-making, and cogniti ve\\nreﬂection (as deﬁned by not accepting the intuitive answer)\\ndid not provide any additional predictive power.\\nWhile there is disagreement about the extent to which cur-\\nrent CR T questions are distinct from numeracy , it is clear\\nthat numeracy is one component of performance. Thus,\\nthere are two major issues for cognitive reﬂection research\\nusing the CR T going forward: 1) over-exposure to the CR T\\nmay undermine data validity , and 2) it is difﬁcult to disen-\\ntangle cognitive reﬂection from numeracy; using math prob-\\nlems means that the CR T is probably affected by speciﬁc\\nknowledge acquired in school. T o help address these issues,\\nwe sought to develop and validate new CR T questions to\\ncontribute to the set of available questions. Our questions\\naddress the noted need for more verbal CR T -type questions\\n(Baron et al., 2015), in an attempt to help researchers ex-\\namine the effects of cognitive reﬂection in the absence of\\nnumeracy confounds.\\n2 The CRT -2\\nW e developed a set of cognitive reﬂection items (called the\\nCR T -2) that were similar in structure to the original CR T .\\nThe CR T -2 consists of four short questions that generate an\\ninitial intuitive, but incorrect, answer. The questions we re\\nfound by searching for “trick questions” and “brain teasers ”\\nonline. The questions have high face validity , and, in or-\\nder to address some criticisms of the original CR T , do not\\nrequire a high degree of mathematical sophistication to gen -\\nerate the correct answer. They are as follows:\\n• If you’re running a race and you pass the person in sec-\\nond place, what place are you in? (intuitive answer:\\nﬁrst; correct answer: second) 3\\n• A farmer had 15 sheep and all but 8 died. How many\\nare left? (intuitive answer: 7; correct answer: 8) 4\\n• Emily’s father has three daughters. The ﬁrst two are\\nnamed April and May . What is the third daugh-\\nter’s name? (intuitive answer: June; correct answer:\\nEmily)3\\n• How many cubic feet of dirt are there in a hole that is 3’\\ndeep x 3’ wide x 3’ long? (intuitive answer: 27; correct\\nanswer: none) 3 ,4\\n3 Study 1\\nStudy 1 had two goals: 1) to ascertain the extent of subject\\npool pollution in two subpopulations of workers in Ama-\\n3 Adapted from Forbes (2012). May not be original source but so urces\\nnot cited.\\n4 Adapted from Riordan (n.d.). May not be original source but s ources\\nnot cited.'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript 9.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2016-01-27T12:06:33-05:00', 'moddate': '2016-01-27T12:06:33-05:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': 'data\\\\Cognitive.pdf', 'total_pages': 15, 'page': 3, 'page_label': '102'}, page_content='Judgment and Decision Making, V ol. 11, No. 1, January 2016 Alternate form of the CR T 102\\nzon’s Mechanical Turk, and 2) to determine whether MTurk\\nsubjects had been less exposed to the items of the CR T -2.\\n3.1 Procedure\\nSubjects. T wo hundred workers on Amazon’s Mechani-\\ncal Turk participated in the study . Because researchers can\\nrestrict the types of eligible workers and thus sample diffe r-\\nent populations, 100 responses were collected from a batch\\nof Masters workers 5 (Masters-required sample), and 100 re-\\nsponses were collected from a batch that did not require\\na Masters certiﬁcation (Masters-optional sample). Batche s\\nwere launched simultaneously , and workers were prevented\\nfrom taking both surveys using the Unique Turker Service\\nwebsite (http://uniqueturker.myleott.com/). In both poo ls,\\nwe restricted access to only workers who have at least a 95%\\napproval rating, since this is a commonly used restriction\\n(e.g., Chandler et al., 2014; Berinsky et al., 2012).\\nProcedure. Subjects answered the original CR T , CR T -2,\\nand four decoy questions (Appendix B) intermixed in a ran-\\ndom order chosen for each subject. Decoy questions were\\nincluded to determine the rate of overclaiming prior expo-\\nsure. They were written to have a similar format to the CR T\\nand CR T -2 questions, be easy to answer, and be completely\\nnovel so that subjects could not have seen them before. Im-\\nmediately after each item, subjects were asked whether they\\nhad seen that question prior to taking the survey .\\n3.2 Results\\nOne subject from the Masters-optional sample was removed\\nfrom analysis for apparently random responding.\\nA very high percentage of subjects had been exposed to at\\nleast one question from the CR T: 62.6% from the Masters-\\noptional and 94.0% from the Masters-required sample. For\\nthe CR T -2, 17.2% of the Masters-optional sample and\\n29.0% of the Masters-required sample had been exposed to\\nat least one of the questions. Crucially , subjects were less\\nlikely to have been exposed to the CR T -2 than to the CR T in\\nboth the Masters-optional sample, t(98) = 7.406, p < .001,\\nand the Masters-required sample, t(99) = 13.559, p < .001.\\nOverclaiming of prior exposure was minimal; only 2.0%\\nof the Masters-optional sample and 0.0% of the Masters-\\nrequired sample reported having seen any of the decoy ques-\\ntions before.\\nThe total number of questions subjects had previously\\nseen from the CR T and the CR T -2 was also analyzed. Sub-\\n5 Masters workers obtain their certiﬁcations by completing a w ide va-\\nriety of different types of jobs with high accuracy and thus ma y provide\\nhigher quality data, but data collection using Masters is sl ower and Mas-\\nters tend to command higher payments. Since workers need to compl ete a\\nhigh volume of tasks to obtain a Masters certiﬁcate, they may ha ve more\\nexposure to common experimental paradigms.\\nFigure 1: Percentage of subjects exposed to 0, 1, 2, 3 or 4\\nquestions. T op panel is CR T . Bottom panel is CR T -2.\\n0 1 2 3\\nMasters optional\\nMasters required\\n0 20 40 60 80 100\\n0 1 2 3 4\\nMasters optional\\nMasters required\\n0 20 40 60 80 100\\njects recognized fewer questions on average from the CR T -2\\n(M = .30) than the CR T (M = 1.65) in the Masters-optional\\nsample, t(98) = 8.915, p < .001, and also recognized fewer\\nquestions from the CR T -2 (M = .40) than the CR T (M =\\n2.60) in the Masters-required sample, t(99) = 21.063, p <\\n.001. However, most subjects who reported prior exposure\\nto any of the CR T questions reported exposure to all three\\n(but this was not true for the CR T -2; see Figure 1). Gener-\\nally , there were not strong differences in exposure between\\nthe individual CR T and CR T -2 questions.\\n3.3 Discussion\\nAnecdotally , it is well-known among researchers in judg-\\nment and decision-making that MTurk is a corrupted sub-\\nject pool for studying cognitive reﬂection. This issue has\\nbeen discussed in publications (T oplak, W est & Stanovich,\\n2014; Baron et al., 2015; Chandler et al., 2014), but never\\nempirically tested. The present results conﬁrm that expo-\\nsure rates to the CR T are remarkably high. Although there\\nis some reported exposure to the CR T -2, the exposure rates\\nare far lower, indicating that it might help address this pro b-\\nlem. However, although the questions have high face valid-\\nity , they require validation before they can be used in place\\nof the original CR T questions.'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript 9.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2016-01-27T12:06:33-05:00', 'moddate': '2016-01-27T12:06:33-05:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': 'data\\\\Cognitive.pdf', 'total_pages': 15, 'page': 4, 'page_label': '103'}, page_content='Judgment and Decision Making, V ol. 11, No. 1, January 2016 Alternate form of the CR T 103\\n4 Study 2\\nStudy 1 conﬁrmed that subject pool pollution is stronger for\\nthe CR T than the CR T -2 questions. In Study 2, we asked\\nwhether the CR T -2 is similar to the CR T in its relationships\\nto other cognitive measures. W e also sought to test our in-\\ntuition that the CR T -2 questions do not require the same nu-\\nmerical sophistication to answer as the original CR T by ex-\\namining the CR T -2’s relationship with numeracy . Although\\nwe originally set out to investigate the CR T -2 questions, we\\nalso found that belief bias fared equally well as a source of\\nitems to measure cognitive reﬂection.\\n4.1 Method\\nSubjects. 143 subjects from the UCLA undergraduate\\nsubject pool completed the study ( M age = 20.50 years, SD\\n= 2.686; 68% female). The pool consists of students who are\\ncurrently enrolled in undergraduate psychology classes at\\nUCLA and who take part in studies to meet part of a course\\nrequirement or for extra credit. Sample sizes for individ-\\nual items were variable because nine subjects did not ﬁnish\\nthe study (because they exceeded the time limit of the study\\nsession), and some additional cells are missing due to unan-\\nswered questions and uninterpretable responses. Scores fo r\\neach scale were calculated only for subjects who gave an-\\nswers to every question on the scale. Each test was run with\\nall of the data available for that analysis.\\nProcedure. Subjects took the original CR T , the CR T -2,\\nand several other rational thinking measures that have a\\ndemonstrated relationship with CR T scores. Subjects com-\\npleted tasks in the following order: belief bias, numeracy\\nscale, time preference, risk preference, need for cognitio n\\n(short scale), and demographic questions. The CR T and\\nCR T -2 were intermixed with the numeracy questions in a\\nrandom order chosen for each subject, and ﬁve denomina-\\ntor neglect questions were distributed throughout the stud y ,\\nseparated by the other tasks. At the end of the study , sub-\\njects were asked to indicate whether they had seen any of the\\nquestions before and to provide details about which ques-\\ntions they had seen in a free response box. Subjects were\\nalso asked whether they had been trained in logical syllo-\\ngisms, and to provide details about the training. Descrip-\\ntions of each task follow .\\nCRT and CRT -2. The CR T and CR T -2 scores were cal-\\nculated as the number of items correct on each scale. In\\norder to validate that respondents who answered incorrectl y\\nwere tempted by the intuitive lures, a second coding system\\nsplit the responses into three categories: correct, intuit ive er-\\nror, and other, which included both non-intuitive errors an d\\n“I don’t know” type responses.\\nBelief bias. Belief bias is deﬁned as the tendency to be\\ninﬂuenced by the believability of the conclusion when eval-\\nuating whether an argument is logically valid. Subjects in-\\ndicated whether eight logical syllogisms were valid or in-\\nvalid. As in T oplak et al. (2014a), the syllogisms were\\nadapted from Markovits and Nantel (1989; see Appendix\\nC for items). Every syllogism had either an invalid argu-\\nment paired with a believable conclusion or a valid argu-\\nment paired with an unbelievable conclusion. Subjects had\\nto check a box indicating they understood the instructions\\nand were informed that an experimenter was nearby to an-\\nswer questions.\\nNotably , correctly answering a belief bias question re-\\nquires overcoming an intuitive reaction to respond based on\\nhow believable the conclusion is. Baron et al. (2015) actu-\\nally included belief bias items in their extended CR T mea-\\nsure, ﬁnding that the belief bias items predicted moral rea-\\nsoning as well as other CR T items, in addition to having\\ngenerally high correlations with the extended CR T measure.\\nNumeracy scale. Subjects answered three general nu-\\nmeracy questions (Schwartz, W oloshin, Black & W elch,\\n1997), as well as eight additional expanded numeracy ques-\\ntions (Lipkus, Samsa & Rimer, 2001). The general and\\nexpanded scale questions were designed to assess facility\\nwith understanding probability and risk magnitudes, and\\nwith converting numbers between percentage, proportion,\\nand probability formats. For questions that required subje cts\\nto convert formats, responses not reported in the desired fo r-\\nmat were counted incorrect. Responses that did not fully\\nsolve for the answer (e.g., saying “half the time” instead of\\ncalculating an exact number) were also counted incorrect.\\nTime preference. The time preference measure was\\nadapted from Frederick (2005). Frederick administered 17\\nitems (labeled items a-q), including questions asking sub-\\njects to indicate their preference between smaller-sooner\\nrewards and larger-later rewards, along with several other\\nquestion types to deduce subjects’ time preferences. For\\neight of these items, Frederick found a signiﬁcant differen ce\\nbetween the responses of subjects who scored low (0 of 3\\nitems correct) versus those who scored high (3 of 3 items\\ncorrect) on the CR T . Those eight items were administered\\nin the present study (see Appendix D for items). Items n-\\nq were answered on an 11-point scale that ranged from –5\\n(much less than the average person taking this survey today)\\nto +5 (much more than the average person taking this survey\\ntoday).\\nRisk preference. The risk preference measure was\\nadapted from Frederick (2005). Frederick administered 18\\nquestions which asked subjects to choose between sure out-\\ncomes and gambles in the domains of both gains and losses.'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript 9.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2016-01-27T12:06:33-05:00', 'moddate': '2016-01-27T12:06:33-05:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': 'data\\\\Cognitive.pdf', 'total_pages': 15, 'page': 5, 'page_label': '104'}, page_content='Judgment and Decision Making, V ol. 11, No. 1, January 2016 Alternate form of the CR T 104\\nQuestions included three different types of gambles: certa in\\ngains versus higher expected value gambles, certain gains\\nversus lower expected value gambles, and certain losses\\nversus lower expected value gambles. For eleven of these\\nitems, Frederick found a signiﬁcant difference between the\\nresponses of subjects in the low versus high groups on the\\nCR T . Those eleven items were administered (see Appendix\\nE for items). Notably , none of these were certain gains ver-\\nsus lower expected value gamble questions.\\nNeed for cognition scale. Subjects completed the 18-item\\nshort need for cognition scale assessing their tendency to e n-\\ngage in and enjoy effortful thinking (Cacioppo, Petty & Kao,\\n1996), answering on a scale from 1 (extremely uncharacter-\\nistic) to 5 (extremely characteristic).\\nDenominator Neglect. As in T oplak et al. (2014a), ﬁve\\ndenominator neglect problems were adapted from Kirk-\\npatrick and Epstein (1992). Subjects were asked about their\\npreference to select a marble from a small tray which con-\\ntained fewer “winning” marbles but a higher relative likeli -\\nhood of winning (due to the presence of few “losing” mar-\\nbles), or a large tray , with more “winning” marbles but a\\nlower relative chance of winning (due to the presence of\\nmany “losing” marbles). Subjects answered each question\\non a scale from 1 (“I would deﬁnitely pick from the small\\ntray”) to 6 (“I would deﬁnitely pick from the large tray”).\\nSee Appendix F for the denominator neglect questions.\\nDemographic questions. Subjects also answered de-\\nmographic questions indicating their age, gender, year in\\nschool, high school and college GP A, and SA T/ACT score.\\n4.2 Results\\nSubjects on average got 46.3% of the original CR T items\\ncorrect and 56.2% of the CR T -2 items correct. The surpris-\\ningly high scores (relative to pre-established norms) may\\nbe partially due to the fact that the questions were all pre-\\nsented on the same page; once subjects realized that some\\nitems were trick questions, they could change their answers\\nto previous items. The high scores may also be due to prior\\nexperience with the items.\\nAs with the CR T , most errors on the CR T -2 were intuitive\\nerrors. The CR T -2 actually produced fewer other-type re-\\nsponses (M = 3.0%) than the CR T (M = 11.1%), t(140) =\\n4.803, p < .001. See Appendix G for the percentages of re-\\nsponses in each category (correct responses, intuitive err ors,\\nand other).\\nOf the 134 subjects who made it to the end of the study ,\\n45 reported that they had seen some of the questions in the\\nstudy before and 89 reported that they had not. Of those\\n45 subjects who had seen some items before, 7 did not dis-\\nclose which they had seen. Eleven had seen at least one of\\nthe original CR T questions, and another three implied they\\nmight have but didn’t give enough information to deduce\\nwith certainty . Nineteen had seen at least one of the new\\nCR T -2 questions, and another two implied they might have\\nbut didn’t give enough information to know for sure.\\nThe internal consistency of the CR T -2 was somewhat low\\n(α = 0.511), as was the internal consistency of the original\\nCR T ( α = 0.624), but the internal consistency of the seven-\\nitem composite (combining the CR T and CR T -2 into a single\\nmeasure) was acceptable ( α = .705). There was a large cor-\\nrelation between the CR T -2 and the original CR T , r s(136) =\\n.511, p < .001. When corrected for attenuation, this corre-\\nlation is even higher, at .905. (Ordinarily , estimated corr e-\\nlation magnitudes can be weakened by measurement error,\\nand disattenuating correlations corrects for this error.) T able\\n1 shows Spearman correlations among the seven CR T ques-\\ntions as well as with composite scores for the original CR T ,\\nthe CR T -2, and a seven-item composite of all the items. All\\nof the 45 correlations were positive and 42 of the 45 were\\nstatistically signiﬁcant.\\nAs previously mentioned, belief bias items require over-\\ncoming an intuitive tendency to be inﬂuenced by the believ-\\nability of the conclusion rather than the logical validity o f\\nthe argument. Thus, belief bias items might measure the\\nsame construct as CR T items. Baron et al. (2015) included\\nbelief bias items in an expanded CR T , and found that the be-\\nlief bias questions had generally high correlations with th e\\nremainder of the items. Similarly , there was a .558 corre-\\nlation between belief bias and the CR T in the present study\\n(disattenuated correlation = .752). Adding the belief bias\\nitems to the CR T increased the reliability ( α = .880), as did\\nadding the belief bias items to the CR T -2 ( α = .851). Cron-\\nbach’s alpha for all three measures combined was .874. For\\nthe belief bias items alone, α = .882. Thus, although we set\\nout only to investigate the suitability of the CR T -2 questio ns\\nas additional CR T items, in the remaining sections we also\\nanalyzed the belief bias items for this purpose.\\nNumeracy . Numeracy scores were calculated as the sum\\nof all correct responses to both Schwartz et al. ’s (1997) gen -\\neral numeracy scale and Lipkus et al. ’s (2001) expanded\\nnumeracy scale. The mean numeracy score was 9.23 out\\nof 11 (SD = 1.948, N = 141) and Cronbach’s alpha was\\n.719. There was a signiﬁcant correlation between the orig-\\ninal CR T and numeracy , r s(136) = .576, p < .001 (disatten-\\nuated correlation = .860), as well as a signiﬁcant correla-\\ntion between the CR T -2 and numeracy , r s(139) = .307, p\\n< .001 (disattenuated correlation = .506). Hoerger’s (2013 )\\ncorrected version of Steiger’s (1980) z-score revealed tha t\\nthe correlation between the CR T -2 and numeracy was sig-\\nniﬁcantly weaker than the correlation between the original\\nCR T and numeracy , Z H (135) = 3.67, p < .001. 6 This sup-\\n6 Because of missing data, sample sizes were unequal for each cor re-\\nlation calculated. Therefore, in calculating Hoerger’s up dated versions of'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript 9.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2016-01-27T12:06:33-05:00', 'moddate': '2016-01-27T12:06:33-05:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': 'data\\\\Cognitive.pdf', 'total_pages': 15, 'page': 6, 'page_label': '105'}, page_content='Judgment and Decision Making, V ol. 11, No. 1, January 2016 Alternate form of the CR T 105\\nT able 1: Intercorrelations (Spearman) among CR T and CR T -2.\\nItem 7-item\\ncomp CR T CR T -2 CR T Q1 CR T Q2 CR T Q3 CR T -2 Q2 CR T -2 Q3 CR T -2 Q4\\nCR T .884∗∗∗ – – – – – – – –\\nCR T -2 .848∗∗∗ .511∗∗∗ – – – – – – –\\nCR T Q1 .623∗∗∗ .753∗∗∗ .314∗∗∗ – – – – – –\\nCR T Q2 .664∗∗∗ .708∗∗∗ .415∗∗∗ .265∗∗∗ – – – – –\\nCR T Q3 .711∗∗∗ .800∗∗∗ .419∗∗∗ .405∗∗∗ .384∗∗∗ – – – –\\nCR T -2 Q1 .597∗∗∗ .380∗∗∗ .670∗∗∗ .309∗∗∗ .300∗∗∗ .211∗ – – –\\nCR T -2 Q2 .466∗∗∗ .300∗∗∗ .533∗∗∗ .119 .240 ∗∗ .305∗∗∗ .159+ – –\\nCR T -2 Q3 .613∗∗∗ .369∗∗∗ .732∗∗∗ .215∗ .249∗∗ .361∗∗∗ .287∗∗∗ .233∗∗∗ –\\nCR T -2Q4 .462∗∗∗ .274∗∗∗ .563∗∗∗ .189∗ .253∗∗ .198∗ .139+ 1.97∗ .224∗∗\\n+ p ≤ .10; ∗ , p ≤ .05; ∗∗ , p ≤ .01; ∗∗∗ , p ≤ .001.\\nports the notion that the CR T -2 does not rely as strongly on\\nnumeracy as the original CR T . However, it is worth noting\\nthat these correlations may be underestimated due to a ceil-\\ning effect on the numeracy measure.\\nThere was also a signiﬁcant correlation between belief\\nbias and numeracy , r s(139) = .466, p < .001 (disattenuated\\ncorrelation = .585). Although the correlation between be-\\nlief bias and numeracy was not signiﬁcantly weaker than the\\ncorrelation between the CR T and numeracy , the relationship\\nshowed a trend in that direction, Z H = 1.67, p < .10. Be-\\ncause the belief bias scale had a higher reliability than the\\nCR T , the strength of its correlation with numeracy may have\\nbeen artiﬁcially inﬂated relative to the strength of the cor re-\\nlation between the CR T and numeracy . When disattenuated\\ncorrelations were compared, belief bias was less correlate d\\nwith numeracy than the original CR T . Thus, like the CR T -\\n2, belief bias items appear useful in disentangling cogniti ve\\nreﬂection and numeracy .\\nScoring and descriptive statistics of rational thinking\\nmeasures. Composite scores for all scales were calculated\\nonly for subjects who provided responses to all questions in\\nthe scale.\\nBelief bias was calculated as the number of correct re-\\nsponses. The mean belief bias score was 4.85 out of 8 (SD\\n= 2.853, N= 143), with a Cronbach’s alpha of .882.\\nNeed for cognition and denominator neglect scores were\\nboth calculated by summing the ratings from each question.\\nThe mean need for cognition score was 60.36 (SD = 9.830,\\nN = 134); the range of possible scores is between 18 and 90,\\nand higher scores indicate higher need for cognition. Cron-\\nbach’s alpha was .848. The mean denominator neglect score\\nwas 11.69 (SD = 5.278, N = 139); the range of possible\\nSteiger’s Z-scores, we used the smaller sample size.\\nscores was from 5 to 30, with higher scores indicating more\\ndenominator neglect. Cronbach’s alpha was .722.\\nThe mean reported university GP A was 3.35. SA T scores\\nare calculated on a scale from 600 to 2400. The distribution\\nof reported SA T scores was bimodal. The most commonly\\nselected SA T score ranges were 1900–1990 and 2100–2190,\\neach with 15.6% of responses. Subjects were assigned a\\nnumerical score from one to 18 based on their selected score\\nbracket (from 18 equal brackets each spanning 100 points).\\nBecause risk preference and time preference measures\\ncontained more than one question type, each question’s re-\\nlationship with the CR T and CR T -2 was examined individu-\\nally rather than creating a composite measure. For risk pref -\\nerence items in the domain of gains (items a-h), the percent-\\nage that chose the risky option ranged from 10.8% to 79.9%.\\nFor risk preference items in the domain of losses (items o-\\nr), the percentage that chose the risky option ranged from\\n24.5% to 49.6%. 7 Subscales were also created to conduct\\nreliability analyses and gender analyses, and for inclusio n\\nin a correlation matrix. Cronbach’s alpha for a subscale of\\nthe eight gains items was .652; Cronbach’s alpha for a sub-\\nscale of the three losses was .539.\\nFor time preference items a-c, 28.4% to 88.7% of subjects\\nselected the deferred option. 8 An attempt to create subscales\\nreinforced the need to analyze items individually . Three\\nsubscales were created: ﬁnancial (items a, b, and c), free\\nestimation (items l and m), and self-comparison (items n, p,\\n7 The percentages choosing the risky option were, respective ly: a 72.7%,\\nb 79.9%, c 30.2%, d 28.8%, e 12.2%, f 10.8%, g 56.8%, h 12.2%, o 2 4.5%,\\nq 30.9%, r 49.6%.\\n8 One subject’s response to question c was excluded as nonsens ical\\nbased on a judgment call from a coder naïve to the study . Means o r per-\\ncents of the time-preference responses were as follows: a 88. 7%; b 28.4%;\\nc 59.6%; l $12.15 (s.d., 9.18); m $103.16 (s.d., 55.43); n 0.6 6 (s.d., 2.23);\\np 2.64 (s.d., 1.68); q –0.15 (2.50).'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript 9.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2016-01-27T12:06:33-05:00', 'moddate': '2016-01-27T12:06:33-05:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': 'data\\\\Cognitive.pdf', 'total_pages': 15, 'page': 7, 'page_label': '106'}, page_content='Judgment and Decision Making, V ol. 11, No. 1, January 2016 Alternate form of the CR T 106\\nT able 2: Spearman correlations with measured of rational th inking (disattenuated results in parentheses)\\nRational thinking measure CR T r s CR T -2 rs BB r s\\nZ (CR T vs.\\nCR T -2)\\nZ (CR T vs.\\nBB)\\nBelief bias .558∗∗∗ (.752) .420 ∗∗∗ (.626) 1.94 +\\nNeed for cognition .203∗ (.279) .236 ∗∗ (.359) .224 ∗∗ (.259) –0.39 –0.26\\nDenominator neglect –.371 ∗∗∗ (–.553) –.241 ∗∗ (–.397) –.363 ∗∗∗ (–.455) –1.62 –0.11\\nSA T scores .588∗∗∗ .376∗∗∗ .494∗∗∗ 2.60∗∗ 1.27\\nCollege GP A .331∗∗∗ .268∗∗∗ .434∗∗∗ 0.76 –1.36\\n+ p ≤ .10; ∗ , p ≤ .05; ∗∗ , p ≤ .01; ∗∗∗ , p ≤ .001.\\nand q). 9 However, Cronbach’s alphas were so low that these\\nsubscales were not used (.465 for ﬁnancial subscale, .358\\nfor free estimation, and –0.61 for self-comparison). The\\nlow alphas reﬂect the notorious difﬁculty of measuring time\\npreference and the small number of items in each subscale.\\nThus, gender analyses were conducted by analyzing each\\ntime preference item separately and time preference is not\\nincluded in a correlation matrix.\\nRelationship of CRT , CRT -2, and belief bias with ra-\\ntional thinking measures. Previously observed correla-\\ntions of the original CR T with belief bias (T oplak et al.,\\n2014a), need for cognition (Frederick, 2005; T oplak et al.,\\n2014a), and denominator neglect (T oplak et al., 2014a) were\\nreplicated, and corresponding correlations were observed\\nbetween the CR T -2 and these scales. There were signiﬁ-\\ncant correlations between the CR T and both SA T scores and\\ncollege GP A, and also between the CR T -2 and both SA T\\nscores and college GP A, consistent with several other stud-\\nies suggesting that CR T scores are related to cognitive abil -\\nity (Frederick, 2005; Obrecht et al., 2009). Steiger’s Z-te st\\nfor the difference of dependent correlations did not reveal\\nsigniﬁcant differences between the CR T and the CR T -2 in\\nthe strength of their correlations with belief bias, need fo r\\ncognition, denominator neglect, or GP A but the CR T was\\nsigniﬁcantly more correlated with SA T scores than the CR T -\\n2. T able 2 shows Spearman correlations of the original CR T\\nand the CR T -2 with the rational thinking measure scores as\\nwell as Z-values from tests of differences in dependent cor-\\nrelations.\\nW e also investigated the relationship between belief bias\\nand other rational thinking measures. There were signif-\\nicant correlations between belief bias and need for cogni-\\ntion, denominator neglect, SA T scores, and college GP A. T a-\\nble 2 also shows Spearman correlations of belief bias (BB)\\nwith the other rational thinking measure scores as well as\\nZ-values from tests of differences in dependent correlatio ns\\n9 Items m and n were reverse-scored in the subscales. Items l and m were\\nz-scored and the z-scores were added to create the free estima tion subscale.\\nbetween BB and CR T . T able 3 shows a full correlation ma-\\ntrix for belief bias along with other rational thinking mea-\\nsures. There were no signiﬁcant differences between belief\\nbias and the original CR T in the strength of their correla-\\ntions with the remaining rational thinking measures when\\nperformed on either the original or the disattenuated corre -\\nlations.\\nFrederick’s (2005) ﬁndings for risk preference and time\\npreference were not fully replicated. Frederick compared\\nthe responses of subjects in a low CR T group (0/3 items\\ncorrect, 33% of respondents) with those from a high CR T\\ngroups (3/3 items correct, 17% of overall respondents).\\nHowever, instead of using a high-low split we calculated\\ncorrelations because our sample size was much smaller and\\nbecause dichotomous measures have been criticized for sac-\\nriﬁcing statistical power (e.g., Irwin & McClelland, 2001,\\n2003; Jaccard et al., 2006; MacCallum, Zhang, Preacher &\\nRucker, 2002) and creating spurious effects (Maxwell & De-\\nlaney , 1993; V argha, Rudas, Delaney & Maxwell, 1996).\\nFor the original CR T , only 1/11 risk preference items and\\n3/8 time preference items were signiﬁcant (all signiﬁcant i n\\nthe expected direction). For the CR T -2, none of the risk pref -\\nerence items were signiﬁcant and 1/8 time preference items\\nwas signiﬁcant (in the expected direction). 10 However, it is\\npossible that the smaller sample size, the difference in ana l-\\nysis strategy , or the fact that we used only a subset of the\\noriginal items contributes to differences in the results. S im-\\nilarly , there were no signiﬁcant correlations between beli ef\\nbias and any of the risk preference items, but belief bias was\\nsigniﬁcantly correlated with 5/8 time preference items. Se e\\nAppendix H for Spearman correlations of the CR T , the CR T -\\n2, and belief bias with risk preference items and time pref-\\nerence items.\\nGender differences. Men (M = 65.9% correct) signiﬁ-\\ncantly outperformed women (M = 36.0% correct) on the\\noriginal CR T , t(129) = 4.579, p < .001, replicating previous\\n10 There were no signiﬁcant correlations between any of the thr ee scales\\n(CR T , CR T -2, or BB) with either of the two risk preference sub scales (gains\\nand losses).'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript 9.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2016-01-27T12:06:33-05:00', 'moddate': '2016-01-27T12:06:33-05:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': 'data\\\\Cognitive.pdf', 'total_pages': 15, 'page': 8, 'page_label': '107'}, page_content='Judgment and Decision Making, V ol. 11, No. 1, January 2016 Alternate form of the CR T 107\\nT able 3: Spearman correlation matrix including belief bias and rational thinking measures.\\nCR T CR T -2 7-item BB Comp. NFC DN NS RP-gain RP-loss SA T\\nCR T -2 . 511∗∗∗ . . . . . . . . .\\n7-item Comp. . 884∗∗∗ . 848∗∗∗ . . . . . . . .\\nBB Comp. . 558∗∗∗ . 420∗∗∗ . 594∗∗∗ . . . . . . .\\nNFC . 203∗ . 236∗∗ . 247∗∗ . 224∗∗ . . . . . .\\nDN − . 371∗∗∗ − . 241∗∗ − . 375∗∗∗ − . 363∗∗∗ − . 146+ . . . . .\\nNS . 576∗∗∗ . 307∗∗∗ . 517∗∗∗ . 466∗∗∗ . 005 − . 247∗∗ . . . .\\nRP-gains . 123 . 017 . 090 . 118 . 106 − . 317∗∗∗ . 192∗ . . .\\nRP-losses . 166+ . 114 . 137 . 033 . 142 . 027 . 014 − . 122 . .\\nSA T . 588∗∗∗ . 376∗∗∗ . 588∗∗∗ . 494∗∗∗ . 039 − . 270∗∗ . 554∗∗∗ . 182+ − . 038 .\\nGP A . 331∗∗∗ . 268∗∗ . 372∗∗∗ . 434∗∗∗ . 059 − . 152 . 455∗∗∗ . 230∗∗ − . 064 . 525∗∗∗\\n+, p ≤ .10, ∗ , p ≤ .05; ∗∗ , p ≤ .01; ∗∗∗ , p ≤ .001.\\nTime preference is not included due to low reliabilities of t he subscales.\\nﬁndings (Frederick, 2005), but men (M = 60.5% correct) and\\nwomen (M = 53.3% correct) were not reliably different on\\nthe CR T -2, t(131) = 1.406, p > .05. See Appendix I for an\\nanalysis of gender differences on individual test question s\\nand gender differences on rational thinking measures.\\nThe typical gender difference has not been fully ex-\\nplained, but some researchers have speculated that it may\\nbe due to differences in numeracy , which is usually higher\\nin men (Frederick, 2005; Baron et al., 2015). This expla-\\nnation would ﬁt well with the present data since the CR T -2\\nrelies less on numeracy than the original CR T . There was\\nnot a statistically signiﬁcant difference in belief bias sc ores\\nbetween men (M = 5.44) and women (M = 4.48), but there\\nwas a trend for men to score higher, t(132) = 1.821, p < .10.\\nT raining in logical syllogisms. Prior exposure may prove\\nto be less problematic for belief bias items than for items\\nsimilar in structure to the original CR T items, since new\\nquestions can be easily generated by using the same struc-\\nture with different content. However, previous training in\\nlogical syllogisms might undermine the validity of belief\\nbias questions. W e computed a rational thinking composite\\nscore equivalent to that used to examine the effects of prior\\nexposure on the CR T’s validity (reported in the introduc-\\ntion), but with belief bias necessarily eliminated from the\\ncomposite. Thus, we added the Z-scores from the need for\\ncognition, denominator neglect, and numeracy scales, with\\ndenominator neglect reverse-scored.\\nSubjects who reported prior training in logical syllogisms\\nanswered more belief bias items correctly (M = 5.63) than\\nthose who did not (M = 4.46), t(132) = 2.164, p < .05. Belief\\nbias scores were signiﬁcantly correlated with performance\\non a rational thinking composite only for subjects who did\\nnot report training in logical syllogisms, r s(92) = .431, p <\\n.001. Belief bias scores did not signiﬁcantly predict ratio -\\nnal thinking composite scores for subjects who had received\\nprior training, though the data were trending, r s(36) = .293,\\np < .10. These results indicate cause for concern, but are not\\nentirely conclusive, since a Fisher’s R to Z transformation\\ndid not reveal a signiﬁcant difference in the strengths of th e\\ntwo correlations, Z = 0.80, p > .05.\\n5 Discussion\\nThe CR T is a tremendously inﬂuential measure of reﬂec-\\ntive thinking and has been widely applied in the study of\\nheuristics and biases. Unfortunately , its prevalence has l ed\\nto the contamination of common subject pools. The results\\nshowed that in one popular pool of subjects as many as 94%\\nof subjects have been exposed to the questions. W e con-\\nﬁrmed that prior exposure inﬂates scores. Moreover, the\\noriginal CR T relies heavily on numeracy , which can create\\nproblems for certain theoretical purposes. T o resolve thes e\\nissues, we developed a new set of questions to measure cog-\\nnitive reﬂection called the CR T -2.\\nIn addition to having high face validity , there is good rea-\\nson to believe that the CR T -2 measures the same construct\\nas the original CR T . The two measures are highly correlated\\nand inclusion of CR T -2 questions in a scale with the CR T\\nincreases the internal reliability of the measure. Further , the\\nCR T -2 predicts performance on the same cognitive measures\\nas the CR T (belief bias, denominator neglect, need for cog-\\nnition, SA T scores, and college GP A). While the studies did\\nnot show a consistent relationship between the CR T -2 and\\nrisk preference or time preference, the data did not repli-\\ncate Frederick’s (2005) original ﬁnding that risk preferen ce\\nand time preference are correlated with the original CR T . A'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript 9.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2016-01-27T12:06:33-05:00', 'moddate': '2016-01-27T12:06:33-05:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': 'data\\\\Cognitive.pdf', 'total_pages': 15, 'page': 9, 'page_label': '108'}, page_content='Judgment and Decision Making, V ol. 11, No. 1, January 2016 Alternate form of the CR T 108\\nsmaller sample size, the use of only a subset of the original\\nitems, a role for numeracy in time preference, or the use of\\ndifferent statistical procedures may account for these dif fer-\\nences.\\nAlthough the CR T -2 does display a signiﬁcant relation-\\nship with numeracy , this is unsurprising given that numer-\\nacy correlates with measures of intelligence such as SA T\\nscores (Peters et al., 2006) and Raven’s Advanced Progres-\\nsive Matrices (Liberali et al., 2012). Importantly , the CR T -2\\nwas signiﬁcantly less reliant on numeracy than the original\\nCR T , which may help researchers who are trying to disso-\\nciate those constructs (Sinayev & Peters, 2015; Böckenholt ,\\n2012; Campitelli & Gerrans, 2014; Baron et al., 2015; Lib-\\nerali et al., 2012; Graffeo, Polonio & Bonini, 2015; W elsh\\net al., 2013). Further, there was no signiﬁcant gender diffe r-\\nence in CR T -2 scores, in contrast to gender differences in th e\\noriginal CR T found in both our study and others (e.g., Fred-\\nerick, 2005). Given this, the gender differences typically\\nfound in CR T scores may be due to differences in numeracy\\nrather than differences in reﬂective reasoning. Thus, avoi d-\\ning confounds with numeracy may help researchers develop\\nfuture measures of cognitive reﬂection that don’t display\\ngender differences. Finally , scores on the CR T -2 did not\\nappear prone to ﬂoor effects.\\n5.1 Familiarity and validity\\nAlthough there are reasons to suspect that prior exposure to\\nthe CR T undermines the validity of the test, to our knowl-\\nedge this has not been directly tested. It is possible that ha v-\\ning seen the items before could inﬂate scores in a manner\\nakin to giving subjects the answers. And in fact, research\\nusing measures other than the CR T has shown that prior ex-\\nposure can inﬂate scores (Basso et al., 1999) and attenuate\\neffect sizes (Chandler et al., 2015). However, there are als o\\nreasons why prior exposure might not be problematic for\\nthe CR T , and could even be beneﬁcial. For example, the\\nﬂoor effects found in many populations reduce the predic-\\ntive value of the test. It is possible that prior exposure cou ld\\nmake the CR T easier, thus creating variability .\\nIn order to assess the extent to which prior exposure poses\\na problem for studies using the CR T , we administered the\\nCR T to 200 subjects on MTurk along with a rational think-\\ning battery including many of the same measures used in\\nStudy 2: belief bias, numeracy , denominator neglect, and\\nneed for cognition. In this sample, 56 subjects (28%) re-\\nported prior exposure to none of the three questions, and\\n120 (60%) reported prior exposure to all three. W e con-\\ncentrated on these two groups. 11 The high-exposure group\\nanswered more CR T questions correctly (M = 1.86) than the\\nlow-exposure group (M = 1.29), W elch’s t(118.79) = 3.0345,\\n11 All results reported here are essentially unchanged if we sp lit the sam-\\nple into groups based on prior exposure to 0 versus more than 0 p roblems,\\nor on prior exposure to 0 or 1 versus 2 or 3 problems.\\np = 0.003. Thus, prior exposure did inﬂate CR T scores, in-\\ndicating that scores should not be compared across subjects\\nwith differential levels of prior exposure.\\nThe results were mixed with respect to whether or not\\nprior exposure on the CR T undermines predictive validity .\\nCR T scores signiﬁcantly predicted performance on the ra-\\ntional thinking battery for the low-exposure group, (r = .27 0,\\np = .044), but not quite signiﬁcantly for the high-exposure\\ngroup (r = .165, p = 0.071). The difference between these\\ntwo correlations was not signiﬁcant (by R to Z transforma-\\ntion, p = .51).\\nIndividual correlations with each of the rational thinking\\nmeasures (rather than analyzing a composite) also produced\\ninconclusive results. The high-exposure group showed\\nhigher correlations between CR T and numeracy (NS, .30\\nvs. .23) but lower correlations between CR T and belief bias\\n(BB, .28 vs. .31), between CR T and Need for Cognition\\n(NFC, –.06 vs. .12) and between CR T and denominator ne-\\nglect (DN, –.04 vs. .04). Note that correlations with DN and\\nNFC did not approach signiﬁcance even for the whole sam-\\nple, so it is not clear what to make of these comparisons.\\nThe general result was that none of these differences in cor-\\nrelations approached signiﬁcance. Even regression of the\\nCR T score on all four measures and their interactions with\\nexposure showed no effect whatsoever of the interaction.\\nThus, we have some reason to believe that the CR T’s va-\\nlidity may be undermined by prior exposure, but we have no\\nclear evidence of any effect. T o a ﬁrst approximation, any\\neffect is not very large. W e thus suggest that future studies\\nshould not rely on the original three items if many subjects\\nhave seen them, but we have no reason to seriously question\\nprior results that have ignored the problem of prior exposur e.\\n5.2 Belief bias\\nAlthough our original purpose was to investigate the CR T -2,\\nwe found that belief bias items can also serve as a source\\nof CR T items. Correctly answering belief bias questions re-\\nquires inhibiting an intuitive tendency to evaluate syllog isms\\nbased on the believability of the conclusion rather than the\\nlogical validity of the argument. Belief bias also correlat es\\nhighly with the CR T and predicted performance on the same\\ncognitive measures as the CR T . There was also some sup-\\nport that belief bias is less correlated with numeracy than t he\\noriginal CR T , and thus can likely address the numeracy con-\\nfounds of the original test. Further, gender was only slight ly ,\\nbut not signiﬁcantly , related to performance. (Baron et al. ,\\n2015, also found no relationship between belief bias and\\ngender.)\\nImportantly , while generating new questions that mimic\\nthe format of those on the original CR T is difﬁcult, belief\\nbias questions are relatively easy to write, and so validati ng\\nbelief bias items as CR T questions provides an algorithm for\\nwriting new questions. Thus, we have not only expanded the'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript 9.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2016-01-27T12:06:33-05:00', 'moddate': '2016-01-27T12:06:33-05:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': 'data\\\\Cognitive.pdf', 'total_pages': 15, 'page': 10, 'page_label': '109'}, page_content='Judgment and Decision Making, V ol. 11, No. 1, January 2016 Alternate form of the CR T 109\\npool of CR T items with four additional questions, but also\\nhelped provide support for belief bias as a virtually unlim-\\nited pool of questions. However, the data did suggest that\\nprevious training in logical syllogisms may undermine the\\nvalidity of belief bias items. Further, one potential disad -\\nvantage of using belief bias items is that, unlike questions\\nfrom the original CR T and CR T -2, there are only two pos-\\nsible answer choices, so it is impossible to separate wrong\\nanswers that are the result of accepting the intuitive lure, and\\nthose that result from faulty deliberate reasoning.\\n5.3 Conclusion\\nIn summary , the ﬁeld is badly in need of a larger database of\\nvalidated questions for studying cognitive reﬂection. In a d-\\ndition to cognitive ability , thinking dispositions are cru cial\\nfor understanding individual differences in rational thin king\\n(W est, T oplak & Stanovich, 2008). Researchers are showing\\nincreasing interest in thinking dispositions, and this int er-\\nest is spreading beyond the heuristics-and-biases traditi on\\nto domains like developmental psychology (T oplak, W est\\n& Stanovich, 2014b; Blackwell, Trzesniewski & Dweck,\\n2007; Duckworth & Seligman, 2005; Reyna, Chapman,\\nDougherty & Confrey , 2012). The more CR T questions that\\nare validated, the better off the ﬁeld will be.\\nW e would like to encourage other researchers studying\\ncognitive reﬂection to generate and validate new questions\\nas well. Due to the way research is commonly conducted\\nin the area, subject pools can quickly become polluted as\\nsubjects are exposed to often-used materials. Thus, tests\\nlike the CR T are an expendable resource, and researchers\\nwho are using questions should also be contributing ques-\\ntions of their own. Researchers should also be mindful of\\nthe types of studies they conduct. Running large pilot stud-\\nies and other underdeveloped studies can drain the pool of\\nnaïve subjects for the entire community . Further, although\\nprior exposure may affect the CR T’s validity , the current\\ndata do not provide adequate support. Future work is needed\\nto investigate the effects of prior exposure on validity , an d to\\nexamine more closely the circumstances under which prior\\nexposure is likely to be a problem.\\nReferences\\nAckerman, R. (2014). The diminishing criterion model for\\nmetacognitive regulation of time investment. Journal of\\nExperimental Psychology: General, 143 (3), 1349–1368.\\nAckerman, R., & Zalmanov , H. (2012). The persistence\\nof the ﬂuency-conﬁdence association in problem solving.\\nPsychonomic Bulletin & Review , 19 (6), 1187–1192.\\nBaron, J., Scott, S., Fincher, K. S., & Metz, S. E. (2015).\\nWhy does the Cognitive Reﬂection T est (sometimes) pre-\\ndict utilitarian moral judgment (and other things)? Jour-\\nnal of Applied Research in Memory and Cognition, 4 (3),\\n265–284.\\nBasso, M. R., Bornstein, R. A., & Lang, J. M. (1999).\\nPractice effects on commonly used measures of executive\\nfunction across twelve months. The Clinical Neuropsy-\\nchologist, 13 (3), 283–292.\\nBerinsky , A. J., Huber, G. A., & Lenz, G. S. (2012). Eval-\\nuating online labor markets for experimental research:\\nAmazon.com’s Mechanical Turk. P olitical Analysis,\\n20(3), 351–368.\\nBlackwell, L. S., Trzesniewski, K. H., & Dweck, C. S.\\n(2007). Implicit theories of intelligence predict achieve -\\nment across an adolescent transition: A longitudinal\\nstudy and an intervention. Child Development, 78 (1),\\n246–263.\\nBöckenholt, U. (2012). The cognitive-miser response\\nmodel: T esting for intuitive and deliberative reasoning.\\nPsychometrika, 77 (2), 388–399.\\nCacioppo, J. T . Petty , R.E. & Kao, C.F . (1996). The efﬁcient\\nassessment of need for cognition. Journal of P ersonality\\nAssessment, 48 (3), 306–307.\\nCampitelli, G., & Gerrans, P . (2014). Does the cognitive\\nreﬂection test measure cognitive reﬂection? A mathemat-\\nical modeling approach. Memory and Cognition, 42 (3),\\n434–447.\\nChandler, J., Mueller, P ., & Paolacci, G. (2014). Non-\\nnaivete among Amazon Mechanical Turk workers: Con-\\nsequences and solutions for behavioral researchers. Be-\\nhavioral Research Methods, 46 (1), 112–130.\\nChandler, J., Paolacci, G., Peer, E., Mueller, P ., & Ratliff , K.\\nA. (2015). Using nonnaive participants can reduce effect\\nsizes. Psychological Science, 26 (7), 1131–1139.\\nCokely , E. T ., & Kelley , C. M. (2009). Cognitive abilities\\nand superior decision making under risk: A protocol anal-\\nysis and process model evaluation. Judgment and Deci-\\nsion Making, 4 (1), 20–33.\\nDel Missier, F ., Mäntylä, T ., & Bruine de Bruin, W .\\n(2012). Decision-making competence, executive func-\\ntioning, and general cognitive abilities. Journal of Be-\\nhavioral Decision-Making, 25 (4), 331–351.\\nDe Neys, W ., & Franssens, S. (2009). Belief inhibition dur-\\ning thinking: Not always winning but at least taking part.\\nCognition, 113 (1), 45–61.\\nDuckworth, A. L., & Seligman, M. E. P . (2005). Self-\\ndiscipline outdoes IQ in predicting academic performance\\nof adolescents. Psychological Science, 16, 939–944.\\nFinucane, M. L., & Gullion, C. M. (2010). Developing a\\ntool for measuring the decision-making competence of\\nolder adults. Psychology and Aging, 25 (2), 271.\\nFrederick, S. (2005). Cognitive reﬂection and decision-\\nmaking. Journal of Economic P erspectives, 19 (4), 25–42.\\nGraffeo, M., Polonio, L., & Bonini, N. (2015). Individual\\ndifferences in competent consumer choice: The role of'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript 9.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2016-01-27T12:06:33-05:00', 'moddate': '2016-01-27T12:06:33-05:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': 'data\\\\Cognitive.pdf', 'total_pages': 15, 'page': 11, 'page_label': '110'}, page_content='Judgment and Decision Making, V ol. 11, No. 1, January 2016 Alternate form of the CR T 110\\ncognitive reﬂection and numeracy skills. Frontiers in Psy-\\nchology, 6 , 844.\\nHoerger, M. (2013). ZH: An updated version of Steiger’s\\nZ and web-based calculator for testing the statistical\\nsigniﬁcance of the difference between dependent cor-\\nrelations. Retrieved from http://www .psychmike.com/\\ndependent_correlations.php.\\nHoppe, E. I., & Kusterer, D. J. (2011). Behavioral biases\\nand cognitive reﬂection. Economics Letters, 110 (12), 97–\\n100.\\nIrwin, J. R. & McClelland, G. H. (2001). Misleading heuris-\\ntics and moderated multiple regression models. Journal\\nof Marketing Research , 38(1), 100–109.\\nIrwin, J. R. & McClelland, G. H. (2003). Negative effects\\nof dichotomizing continuous predictor variables. Journal\\nof Marketing Research, 40 (3), 366–371.\\nJaccard, J., Guilamo-Ramos, V ., Johansson, M., & Bouris,\\nA. (2006). Multiple regression analyses in clinical child\\nand adolescent psychology . Journal of Clinical Child and\\nAdolescent Psychology, 35 (3), 456–479.\\nJohnson-Laird, P . N., & Bara, B. G. (1984). Syllogistic in-\\nference. Cognition, 16, 1–61.\\nKahneman, D. (2011). Thinking, F ast and Slow . New Y ork:\\nFarrar, Strauss, Giroux.\\nKirkpatrick, L., & Epstein, S. (1992). Cognitive-\\nexperiential self-theory and subjective probability: Evi -\\ndence for two conceptual systems. Journal of P ersonality\\nand Social Psychology, 63 (4), 534–544.\\nKoehler, D. J., & James, G. (2010). Probability matching\\nand strategy availability . Memory & Cognition, 38 (6),\\n667–676.\\nLevesque, H. J. (1986). Making believers out of computers.\\nArtiﬁcial Intelligence, 30, 81–108.\\nLevesque, H. J. (1989). Logic and the complexity of rea-\\nsoning. In R. H. Thomason (Ed.), Philosophical logic\\nand artiﬁcial intelligence (pp. 73–107). Dordrecht, The\\nNetherlands: Kluwer Academic Publishers.\\nLiberali, J. M., Reyna, V . F ., Furlan, S., Stein, L. M., &\\nPardo, S. T . (2012). Individual differences in numeracy\\nand cognitive reﬂection, with implications for biases and\\nfallacies in probability judgment. Journal of Behavioral\\nDecision Making, 25 (4), 361–381.\\nLipkus, I. M., Samsa, G., & Rimer, B. K. (2001). General\\nperformance on a numeracy scale among highly educated\\nsamples. Medical Decision Making, 21 (1), 37–44.\\nLubin, G. (2012). A simple logic question that most\\nHarvard students get wrong. Business Insider . Re-\\ntrieved from: http://www .businessinsider.com/question -\\nthat-harvard-students-get-wrong-2012-12.\\nMacCallum, R. C., Zhang, S., Preacher, K. J., & Rucker, D.\\nD. (2002). On the practice of dichotomization of quanti-\\ntative variables. Psychological Methods, 7 (1),19–40.\\nMarkovits, H. & Nantel, G. (1989). The belief-bias effect\\nin the production and evaluation of logical conclusions.\\nMemory & Cognition, 17 (1), 11–17.\\nMaxwell, S. E. & Delaney , H. D. (1993). Bivariate median\\nsplits and spurious statistical signiﬁcance. Psychological\\nBulletin, 113 (1),181–190.\\nObrecht, N., Chapman, G., & Gelman, R. (2007) Intuitive\\nt-tests: Lay use of statistical information. Psychonomic\\nBulletin and Review , 14 (6), 1147–1152.\\nObrecht, N. A., Chapman, G. B., & Gelman, R. (2009). An\\nencounter frequency account of how experience affects\\nlikelihood estimation. Memory & Cognition, 37 (5), 632–\\n643.\\nOechssler, J., Roider, A., & Schmitz, P . W . (2009). Cogni-\\ntive abilities and behavioral biases. Journal of Economic\\nBehavior & Organization, 72 (1), 147–152.\\nPaxton, J. M., Ungar, L., & Greene, J. D. (2012). Reﬂec-\\ntion and reasoning in moral judgment. Cognitive Science,\\n36(1), 163–177.\\nPeters, E. (2012). Beyond comprehension: the role of nu-\\nmeracy in judgments and decisions. Current Directions\\nin Psychological Science, 21 (1), 31–35.\\nPeters, E., Dieckmann, N. F ., Västfjäll, D., Mertz, C. K.,\\nSlovic, P ., & Hibbard, J. H. (2009). Bringing meaning\\nto numbers: the impact of evaluative categories on de-\\ncisions. Journal of Experimental Psychology: Applied,\\n15(3), 213–227.\\nPeters, E.,Västfjäll, D., Slovic, P .,Mertz, C. K., Mazzocc o,\\nK., and Dickert, S. (2006). Numeracy and decision mak-\\ning. Psychological Science, 17 (5), 407–413.\\nPostrel, A. (2006). W ould you take a bird in the hand,\\nor a 75% chance of two in the bush? The New Y ork\\nTimes. Retrieved from: http://www .nytimes.com/2006/\\n01/26/business/26scene.html?pagewanted=print&_r=0.\\nPrimi, C., Morsanyi, K., Chiesi, F ., Donati, M. A., &\\nHamilton, J. (2015). The development and testing of a\\nnew version of the cognitive reﬂection test applying item\\nresponse theory (IR T). Journal of Behavioral Decision\\nMaking. http://dx.doi.org/10.1002/bdm.1883.\\nRand, D. G., Peysakhovich, A., Kraft-T odd, G. T ., New-\\nman, G. E., Wurzbacher, O., Nowak, M.A., & Greene,\\nJ.D. (2014). Social heuristics shape intuitive cooperatio n.\\nNature Communications, 5, 1–30.\\nReyna, V ., Chapman, S., Dougherty , M., & Confrey , J.\\n(Eds.). (2012). The adolescent brain: Learning, rea-\\nsoning, and decision making . W ashington DC: American\\nPsychological Association.\\nReyna,V . F ., Nelson,W . L., Han, P . K., & Dieckmann, N.\\nF . (2009). How numeracy inﬂuences risk comprehension\\nand medical decision making. Psychological Bulletin,\\n135(6), 943–973.\\nRiordan, H. (n.d.). See if you can ﬁgure out these trick\\nquestions. . . Allwomenstalk. Retrieved from http://funny .\\nallwomenstalk.com/see-if-you-can-ﬁgure-out-these-\\ntrick-questions.'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript 9.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2016-01-27T12:06:33-05:00', 'moddate': '2016-01-27T12:06:33-05:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': 'data\\\\Cognitive.pdf', 'total_pages': 15, 'page': 12, 'page_label': '111'}, page_content='Judgment and Decision Making, V ol. 11, No. 1, January 2016 Alternate form of the CR T 111\\nRoyzman, E. B., Landy , J. F ., & Leeman, R. F . (2014). Are\\nthoughtful people more utilitarian? CR T as a unique pre-\\ndictor of moral minimalism in the dilemmatic context.\\nCognitive Science, 39 (2), 325–352.\\nSchwartz, L. M., W oloshin, S., Black, W . C., & W elch, G.\\nH. (1997). The role of numeracy in understanding the\\nbeneﬁt of screening mammography . Annals of Internal\\nMedicine, 127 (11), 966–971.\\nSinayev , A. & Peters, E. (2015). Cognitive reﬂection vs.\\ncalculation in decision making. Frontiers in Psychology,\\n6, 532.\\nSteiger, J. H. (1980). T ests for comparing elements of a\\ncorrelation matrix. Psychological Bulletin, 87 , 245–251.\\nStewart, N., Ungemach, C., Harris, A. J. L., Bartels, D. M.,\\nNewell, B. R., Paolacci, G., & Chandler, J. (2015). The\\naverage laboratory samples a population of 7,300 Ama-\\nzon Mechanical Turk W orkers. Judgment and Decision-\\nMaking, 10 (5), 479–491.\\nT oplak, M. E., & Stanovich, K. E. (2002). The do-\\nmain speciﬁcity and generality of disjunctive reasoning:\\nSearching for a generalizable critical thinking skill. Jour-\\nnal of Educational Psychology, 94 (1), 197–209.\\nT oplak, M. E., W est, R.F ., & Stanovich, K. E. (2011). The\\nCognitive Reﬂection T est as a predictor of performance\\non heuristics-and-biases tasks. Memory & Cognition,\\n39(7),1275–1289\\nT oplak, M. E., W est, R. F ., & Stanovich, K. E. (2014a).\\nAssessing miserly information processing: An expansion\\nof the Cognitive Reﬂection T est. Thinking & Reasoning,\\n20(2), 147–168.\\nT oplak, M. E., W est, R. F ., & Stanovich, K. E. (2014b).\\nRational thinking and cognitive sophistication: Develop-\\nment, cognitive abilities, and thinking dispositions. De-\\nvelopmental Psychology, 50 (4), 1037–1048.\\nV argha, A., Rudas, T ., Delaney , H. D., & Maxwell, S. E.\\n(1996). Dichotomization, partial correlation, and condi-\\ntional independence. Journal of Educational and Behav-\\nioral Statistics, 21 (3), 264–282.\\nW eller, J. A., Dieckmann, N. F ., Tusler, M., Mertz, C. K.,\\nBurns, W . J.,& Peters, E. (2013). Development and test-\\ning of an abbreviated numeracy scale: A Rasch analysis\\napproach. Journal of Behavioral Decision Making, 26 (2),\\n198–212.\\nW elsh, M., Burns, N., & Delfabbro, P . (2013). The cognitive\\nreﬂection test: How much more than numerical ability?\\nPaper presented at the Proceedings of the 35th Annual\\nMeeting of the Cognitive Science Society , Berlin, Ger-\\nmany . pp.1587–1592.\\nW est, R. F ., T oplak, M. E., & Stanovich, K. E. (2008).\\nHeuristics and biases as measures of critical thinking:\\nAssociations with cognitive ability and thinking disposi-\\ntions. Journal of Educational Psychology, 100 (4), 930–\\n941.\\nAppendix A: CRT validity study meth-\\nods\\nT wo hundred subjects on Amazon’s Mechanical Turk com-\\npleted the study . W e restricted the respondents to those\\nwho had at least a 95% approval rate. Subjects were pre-\\nvented from taking more than one related survey in our lab\\nin which the CR T or CR T -2 was administered using the\\nUnique Turker Service (http://uniqueturker.myleott.com /).\\nSubjects ﬁrst answered each of the CR T questions in ran-\\ndom order. After each item, subjects were asked whether\\nthey had seen that item before. Next, subjects took a ra-\\ntional thinking battery including eight belief bias items, the\\n18-item need for cognition scale, and an 11-item numeracy\\nscale. Subjects also provided their gender, and ﬁve denom-\\ninator neglect questions were distributed throughout the r a-\\ntional thinking battery . These same measures are also used\\nand described in more detail in Study 2. Z scores for each\\nof the rational thinking measures were summed to create a\\nrational thinking composite score, with denominator negle ct\\nreverse-scored.\\nAppendix B: Decoy questions\\n1. A cargo hold of a ship had 500 crates of oranges. At the\\nship’s ﬁrst stop, 100 crates were unloaded. At the sec-\\nond stop, 200 more were unloaded. How many crates\\nof oranges were left after the second stop?\\n2. Sara, Emma, and Sophia embark on a river trip. Each\\nof them brings one supply item for the trip: a kayak,\\na cooler of sandwiches, and a bag of apples. Sara\\nbrought the apples and Emma didn’t bring anything ed-\\nible. What did Sophia bring?\\n3. An expedition on a mountain climbing trip was trav-\\neling with eleven horse packs. Each horse can carry\\nonly three packs. How many horses does the expedi-\\ntion need?\\n4. A mechanic shop had ﬁve silver cars, two red cars, and\\none blue car in the garage. During the day , three silver\\ncars and one red car were picked up, and one black car\\nwas dropped off. How many silver cars were in the\\ngarage at the end of the day?\\nAppendix C: Belief bias items\\nFor each of the following problems, decide if the given con-\\nclusion follows logically from the premises. Select YES if,\\nand only if, you judge that the conclusion can be derived\\nunequivocally from the given premises. Otherwise, select\\nNO.\\nDo you understand these instructions? An experimenter\\nis available to answer any questions you may have. Please'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript 9.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2016-01-27T12:06:33-05:00', 'moddate': '2016-01-27T12:06:33-05:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': 'data\\\\Cognitive.pdf', 'total_pages': 15, 'page': 13, 'page_label': '112'}, page_content='Judgment and Decision Making, V ol. 11, No. 1, January 2016 Alternate form of the CR T 112\\nindicate yes only when you feel that you fully understand\\nthe instructions.\\nPremise 1: All things that are smoked are good for the\\nhealth.\\nPremise 2: Cigarettes are smoked.\\nConclusion: Cigarettes are good for the health.\\nPremise 1: All unemployed people are poor.\\nPremise 2: Rockefeller is not unemployed.\\nConclusion: Rockefeller is not poor.\\nPremise 1: All ﬂowers have petals.\\nPremise 2: Roses have petals.\\nConclusion: Roses are ﬂowers.\\nPremise 1: All animals with four legs are dangerous.\\nPremise 2: Poodles are animals that aren’t dangerous.\\nConclusion: Poodles do not have four legs.\\nPremise 1: All mammals walk.\\nPremise 2: Whales are mammals.\\nConclusion: Whales walk.\\nPremise 1: All Eastern countries are communist.\\nPremise 2: Canada is not an Eastern country .\\nConclusion: Canada is not communist.\\nPremise 1: All animals like water.\\nPremise 2: Cats do not like water.\\nConclusion: Cats are not animals.\\nPremise 1: All things that have a motor need oil.\\nPremise 2: Automobiles need oil.\\nConclusion: Automobiles have motors.\\nAppendix D: Time preference items\\na. Which of the following would you prefer, $3400 this\\nmonth or $3800 next month?\\nb. Which of the following would you prefer, $100 now or\\n$140 next year?\\nc. Which of the following would you prefer, $100 now or\\n$1100 in 10 years?\\nl. What is the highest amount of money you would be will-\\ning to pay to have a book shipped overnight rather than in 2\\nweeks?\\nm. What is the smallest amount of money to be received in 4\\ndays that you would prefer to receiving $170 in 2 months? 12\\nn. Compared to the average person taking this survey today ,\\nhow impulsive are you?\\np. Compared to the average person taking this survey today ,\\nhow much do you think about your future?\\n12 In Frederick (2005), for item M subjects speciﬁed the smalles t amount\\nof money they would prefer to receive in 4 days over $170 in two mo nths\\nthrough a series of choices. However, in the current study , s ubjects were\\nasked to simply enter an amount in a free form text input box due t o time\\nconstraints.\\nq. Compared to the average person taking this survey today ,\\nhow much do you worry about inﬂation?\\nAppendix E: Risk preference items\\nWhich of the following would you prefer?\\na. Receiving $1,000 for sure or a 90% chance to receive\\n$5,000\\nc. Receiving $100 for sure or a 90% chance to receive $500\\nc. Receiving $1,000 for sure or a 75% chance to receive\\n$4,000\\nd. Receiving $100 for sure or a 75% chance to receive $200\\ne. Receiving $100 for sure or a 75% chance to receive $150\\nf. Receiving $100 for sure or a 50% chance to receive $300\\ng. Receiving $500 for sure or a 15% chance to receive\\n$1,000,000\\nh. Receiving $100 for sure or a 3% chance to receive $7,000\\no. Losing $100 for sure or a 75% chance to lose $200\\nq. Losing $50 for sure or a 10% chance to lose $800\\nr. Losing $100 for sure or a 3% chance to lose $7000\\nAppendix F: Denominator neglect item\\nformat\\nSubjects responded to ﬁve questions in the following format :\\n“ Assume that you are presented with two trays of black\\nand white marbles (pictured below and right): The large tray\\ncontains 100 marbles. The small tray contains 10 marbles.\\nThe marbles are spread in a single layer in each tray . Y ou\\nmust draw out one marble (without peeking, of course) from\\neither tray . If you draw a black marble you win $5.\\nConsider a condition in which: The small tray contains 1\\nblack and 9 white marbles. The large tray contains 8 black\\nand 92 white marbles.\\nFrom which tray would you prefer to select a marble in a\\nreal situation?”\\nResponses were made on the following six-point scale in-\\ndicating the graded attractiveness of each option.\\n(1) I would deﬁnitely pick from the small tray\\n(2) I would pick from the small tray\\n(3) I would probably pick from the small tray\\n(4) I would probably pick from the large tray\\n(5) I would pick from the large tray\\n(6) I would deﬁnitely pick from the large tray\\nFor the remaining four questions, the ratio of black:white\\nmarbles in the small and large trays were as follows: 1:4\\nversus 19:81, 1:19 versus 4:96, 2:3 versus 19:31, and 3:12\\nversus 18:82.'),\n",
       " Document(metadata={'producer': 'dvips + GPL Ghostscript 9.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2016-01-27T12:06:33-05:00', 'moddate': '2016-01-27T12:06:33-05:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': 'data\\\\Cognitive.pdf', 'total_pages': 15, 'page': 14, 'page_label': '113'}, page_content='Judgment and Decision Making, V ol. 11, No. 1, January 2016 Alternate form of the CR T 113\\nAppendix G: Percentages of responses\\nby type for CRT and CRT -2 questions\\nQuestion Correct Intuitive\\nerrors Other\\nCR T Q1 48.2% 44.0% 7.8%\\nCR T Q2 33.6% 53.1% 13.3%\\nCR T Q3 51.7% 34.3% 14.0%\\nCR T -2 Q1 62.9% 34.3% 2.8%\\nCR T -2 Q2 83.2% 16.1% 0.7%\\nCR T -2 Q3 62.4% 29.1% 8.5%\\nCR T -2 Q4 16.1% 83.9% 0.0%\\nFor the CR T -2 Q3 (Emily’s father), only the month\\n“July” was counted as intuitive-incorrect; other month\\nnames (like “May”) were scored as “other”. For the\\nCR T Q4 (dirt in a hole), any nonzero number was\\ncounted as “intuitive error” due to the high variability\\nin calculation ability .\\nAppendix H: Spearman correlations\\nwith risk preference and time prefer-\\nence items\\nItem CR T CR T -2 BB\\nRisk preference\\na . 048 − . 007 . 013\\nb . 036 . 078 . 049\\nc . 030 − . 049 . 013\\nd . 022 . 030 . 140+\\ne − . 013 − . 033 . 012\\nf . 132 . 145+ . 126\\ng . 216∗ . 019 . 095\\nh . 023 − . 059 . 076\\no . 152+ . 052 − . 004\\nq . 091 . 060 . 025\\nr . 132 . 087 . 043\\nTime preference\\na . 046 − . 075 . 152+\\nb . 170∗ . 142+ . 214∗\\nc − . 006 . 055 . 106\\nl − . 240∗∗ − . 140 − . 198∗\\nm . 092 . 117 . 173∗\\nn − . 251∗∗ − . 198∗ − . 305∗∗∗\\np − . 141 − . 088 − . 246∗∗\\nq − . 101 − . 033 − . 100\\n+, p ≤ .10, ∗ , p ≤ .05; ∗∗ , p ≤ .01; ∗∗∗ , p ≤ .001.\\nAppendix I: Gender differences\\nMale Female T -test result\\nCR T measures (percent correct)\\nCR T Q1 58% 41% t(131) = 1.851, p < .10\\nCR T Q2 56% 22% t(132) = 3.837, p < .001\\nCR T Q3 83% 44% t(130) = 4.954, p < .001\\nCR T -2 Q1 67% 59% t(132) = 0.898, p > .05\\nCR T -2 Q2 93% 78% t(132) = 2.554, p < .05\\nCR T -2 Q3 63% 61% t(131) = 0.185, p > .05\\nCR T -2 Q4 19% 14% t(132) = 0.638, p > .05\\nRational thinking measures (means)\\nNS 9. 86 8 . 86 t(121) = 3.272, p = .001\\nBB 5. 44 4 . 48 t(132) = 1.821, p < .10\\nNFC 61. 56 59 . 81 t(131) = .955, p > .05\\nDN 8. 70 13 . 13 t(132) = –4.878, p < .001\\nGP A 3. 42 3 . 32 t(130) = 1.293, p > .05\\nSA T 14. 97 13 . 94 t(107) = 1.639, p > .05\\nRP gains 3. 65 2 . 79 t(132) = 2.674, p < .01\\nRP losses 0. 98 1 . 08 t(132) = –.538, p > .05\\nTP a 0. 84 0 . 91 t(66) = –1.164, p > .05\\nTP b 0. 30 0 . 27 t(132) = .329, p > .05\\nTP c 0. 60 0 . 58 t(132) = .242, p > .05\\nTP l 10. 29 13 . 24 t(114) = –1.957, p < .10\\nTP m 102. 90 102. 23 t(128) = .063, p > .05\\nTP n 0. 42 0 . 79 t(132) = –.904, p > .05\\nTP p 2. 53 2 . 63 t(132) = –.290, p > .05\\nTP q − 0. 16 − 0. 26 t(132) = .217, p > .05')]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#PROCESS THE PDF\n",
    " #load the pdf now\n",
    "loader = PyPDFLoader(\"data\\\\Cognitive.pdf\")\n",
    "pages =  loader.load()\n",
    "pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "63e81cb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Split the documents into smaller chunks\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=600, chunk_overlap=200)\n",
    "chunks=text_splitter.split_documents(pages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e763c7a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Create Embeddings ##used wrong model at first\n",
    "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
    "\n",
    "def get_embeddings():\n",
    " # Create embeddings using Google Generative AI\n",
    " embeddings = GoogleGenerativeAIEmbeddings(model=\"models/embedding-001\", chunk_size=1, google_api_key=\"AIzaSyDgcB4frVwNLcl0r_HOebtP4VzvovkW9O4\"   )\n",
    " return embeddings\n",
    "embedding_function = get_embeddings()\n",
    "test_vector = embedding_function.embed_query(\"What is the main topic of the pdf?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "857018a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\VishuManjhi\\AppData\\Local\\Temp\\ipykernel_25256\\1972968960.py:4: LangChainDeprecationWarning: Since Chroma 0.4.x the manual persistence method is no longer supported as docs are automatically persisted.\n",
      "  vectorstore.persist() #saved and persisted the vector store although it is not necessary to persist it every time\n"
     ]
    }
   ],
   "source": [
    "##CREATING THE VECTOR STORE using Chroma\n",
    "\n",
    "vectorstore = Chroma.from_documents(documents=chunks, embedding=embedding_function, persist_directory=\"data/chroma_db\") \n",
    "vectorstore.persist() #saved and persisted the vector store although it is not necessary to persist it every time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5319748a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ ChromaDB vector store created and saved.\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# 1. Load environment\n",
    "load_dotenv()\n",
    "api_key = os.getenv(\"GEMINI_API_KEY\")\n",
    "\n",
    "# 2. Load the PDF\n",
    "loader = PyPDFLoader(r\"data\\Cognitive.pdf\")\n",
    "pages = loader.load()\n",
    "\n",
    "# 3. Split into chunks\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=100)\n",
    "chunks = text_splitter.split_documents(pages)  # ✅ this creates the 'chunks' variable\n",
    "\n",
    "# 4. Set up Gemini embeddings\n",
    "embedding_function = GoogleGenerativeAIEmbeddings(\n",
    "    model=\"models/embedding-001\",\n",
    "    google_api_key=api_key\n",
    ")\n",
    "\n",
    "# 5. Create the Chroma vector store\n",
    "def create_vectorstore(chunks, embedding_function,vectorstore_path=\"data/chroma_db\"):\n",
    "    \"\"\"Create and persist a Chroma vector store.\"\"\"\n",
    "    vectorstore = Chroma.from_documents(\n",
    "        documents=chunks,\n",
    "        embedding=embedding_function,\n",
    "        persist_directory=vectorstore_path\n",
    "    )\n",
    "    vectorstore.persist()\n",
    "    return vectorstore\n",
    "vectorstore = Chroma.from_documents(\n",
    "    documents=chunks,\n",
    "    embedding=embedding_function,\n",
    "    persist_directory=\"data/chroma_db\"\n",
    ")\n",
    "\n",
    "# 6. Save it\n",
    "vectorstore.persist()\n",
    "print(\"✅ ChromaDB vector store created and saved.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "724d60a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\VishuManjhi\\AppData\\Local\\Temp\\ipykernel_25256\\2906841462.py:3: LangChainDeprecationWarning: The class `Chroma` was deprecated in LangChain 0.2.9 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-chroma package and should be used instead. To use it run `pip install -U :class:`~langchain-chroma` and import as `from :class:`~langchain_chroma import Chroma``.\n",
      "  vectorstore= Chroma(persist_directory=\"data/chroma_db\", embedding_function=embedding_function )\n"
     ]
    }
   ],
   "source": [
    "##Load Vector Store\n",
    "\n",
    "vectorstore= Chroma(persist_directory=\"data/chroma_db\", embedding_function=embedding_function )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6e99575c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'moddate': '2016-01-27T12:06:33-05:00', 'title': '', 'page_label': '112', 'producer': 'dvips + GPL Ghostscript 9.16', 'page': 13, 'source': 'data\\\\Cognitive.pdf', 'total_pages': 15, 'keywords': '', 'creationdate': '2016-01-27T12:06:33-05:00', 'creator': 'LaTeX with hyperref package', 'subject': '', 'author': ''}, page_content='Conclusion: Canada is not communist.\\nPremise 1: All animals like water.\\nPremise 2: Cats do not like water.\\nConclusion: Cats are not animals.\\nPremise 1: All things that have a motor need oil.\\nPremise 2: Automobiles need oil.\\nConclusion: Automobiles have motors.\\nAppendix D: Time preference items\\na. Which of the following would you prefer, $3400 this\\nmonth or $3800 next month?\\nb. Which of the following would you prefer, $100 now or\\n$140 next year?'),\n",
       " Document(metadata={'keywords': '', 'total_pages': 15, 'creationdate': '2016-01-27T12:06:33-05:00', 'subject': '', 'title': '', 'author': '', 'moddate': '2016-01-27T12:06:33-05:00', 'producer': 'dvips + GPL Ghostscript 9.16', 'creator': 'LaTeX with hyperref package', 'page_label': '112', 'page': 13, 'source': 'data\\\\Cognitive.pdf'}, page_content='Premise 2: Canada is not an Eastern country .\\nConclusion: Canada is not communist.\\nPremise 1: All animals like water.\\nPremise 2: Cats do not like water.\\nConclusion: Cats are not animals.\\nPremise 1: All things that have a motor need oil.\\nPremise 2: Automobiles need oil.\\nConclusion: Automobiles have motors.\\nAppendix D: Time preference items\\na. Which of the following would you prefer, $3400 this\\nmonth or $3800 next month?\\nb. Which of the following would you prefer, $100 now or\\n$140 next year?\\nc. Which of the following would you prefer, $100 now or\\n$1100 in 10 years?'),\n",
       " Document(metadata={'moddate': '2016-01-27T12:06:33-05:00', 'creationdate': '2016-01-27T12:06:33-05:00', 'author': '', 'keywords': '', 'page_label': '112', 'page': 13, 'producer': 'dvips + GPL Ghostscript 9.16', 'subject': '', 'total_pages': 15, 'creator': 'LaTeX with hyperref package', 'title': '', 'source': 'data\\\\Cognitive.pdf'}, page_content='Judgment and Decision Making, V ol. 11, No. 1, January 2016 Alternate form of the CR T 112\\nindicate yes only when you feel that you fully understand\\nthe instructions.\\nPremise 1: All things that are smoked are good for the\\nhealth.\\nPremise 2: Cigarettes are smoked.\\nConclusion: Cigarettes are good for the health.\\nPremise 1: All unemployed people are poor.\\nPremise 2: Rockefeller is not unemployed.\\nConclusion: Rockefeller is not poor.\\nPremise 1: All ﬂowers have petals.\\nPremise 2: Roses have petals.')]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create recieve chunks  ##similarity search uses cosine distance to find similar vectors\n",
    "from langchain_core.runnables import RunnableLambda\n",
    "\n",
    "retriever = vectorstore.as_retriever(searchtype=\"similarity\", search_kwargs={\"k\": 3})\n",
    "retriever_chain = RunnableLambda(lambda x: retriever.get_relevant_documents(x[\"question\"])) ##wrapped around runnableLambda to get relevant documents\n",
    "relevant_docs = retriever.invoke(\"What is the main topic of the pdf?\")\n",
    "relevant_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "383f11f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "##NOW CREATING A PROMPT TEMPLATE\n",
    "Prompt_Template = \"\"\"\n",
    "You are an AI assistant that answers questions based on the provided context.\n",
    "\n",
    "Use the following pieces of context to answer the question at the end.\n",
    "\n",
    "If you don't know the answer, just say that you don't know. Don't try to make up an answer.\n",
    "\n",
    "Context:\n",
    "{context}\n",
    "\n",
    "---\n",
    "\n",
    "Question:\n",
    "{question}\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4ab76123",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Human: \n",
      "You are an AI assistant that answers questions based on the provided context.\n",
      "\n",
      "Use the following pieces of context to answer the question at the end.\n",
      "\n",
      "If you don't know the answer, just say that you don't know. Don't try to make up an answer.\n",
      "\n",
      "Context:\n",
      "Conclusion: Canada is not communist.\n",
      "Premise 1: All animals like water.\n",
      "Premise 2: Cats do not like water.\n",
      "Conclusion: Cats are not animals.\n",
      "Premise 1: All things that have a motor need oil.\n",
      "Premise 2: Automobiles need oil.\n",
      "Conclusion: Automobiles have motors.\n",
      "Appendix D: Time preference items\n",
      "a. Which of the following would you prefer, $3400 this\n",
      "month or $3800 next month?\n",
      "b. Which of the following would you prefer, $100 now or\n",
      "$140 next year?\n",
      "\n",
      "---\n",
      "\n",
      "Premise 2: Canada is not an Eastern country .\n",
      "Conclusion: Canada is not communist.\n",
      "Premise 1: All animals like water.\n",
      "Premise 2: Cats do not like water.\n",
      "Conclusion: Cats are not animals.\n",
      "Premise 1: All things that have a motor need oil.\n",
      "Premise 2: Automobiles need oil.\n",
      "Conclusion: Automobiles have motors.\n",
      "Appendix D: Time preference items\n",
      "a. Which of the following would you prefer, $3400 this\n",
      "month or $3800 next month?\n",
      "b. Which of the following would you prefer, $100 now or\n",
      "$140 next year?\n",
      "c. Which of the following would you prefer, $100 now or\n",
      "$1100 in 10 years?\n",
      "\n",
      "---\n",
      "\n",
      "Judgment and Decision Making, V ol. 11, No. 1, January 2016 Alternate form of the CR T 112\n",
      "indicate yes only when you feel that you fully understand\n",
      "the instructions.\n",
      "Premise 1: All things that are smoked are good for the\n",
      "health.\n",
      "Premise 2: Cigarettes are smoked.\n",
      "Conclusion: Cigarettes are good for the health.\n",
      "Premise 1: All unemployed people are poor.\n",
      "Premise 2: Rockefeller is not unemployed.\n",
      "Conclusion: Rockefeller is not poor.\n",
      "Premise 1: All ﬂowers have petals.\n",
      "Premise 2: Roses have petals.\n",
      "\n",
      "---\n",
      "\n",
      "Question:\n",
      "What is the main topic of the pdf?\n",
      "\n"
     ]
    }
   ],
   "source": [
    "##Creating the actual prompt\n",
    "context_text=\"\\n\\n---\\n\\n\".join([doc.page_content for doc in relevant_docs])\n",
    "\n",
    "#create the prompt\n",
    "prompt_template=ChatPromptTemplate.from_template(Prompt_Template)\n",
    "prompt = prompt_template.format(context=context_text, question=\"What is the main topic of the pdf?\")\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "eabb42e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Based on the provided text, the main topic is logic and reasoning, specifically focusing on deductive reasoning examples and possibly a section on time preference.  There\\'s also a mention of a test (\"CR T 112\").', additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'safety_ratings': []}, id='run--9a565ffe-647c-468c-9174-5680a79b618f-0', usage_metadata={'input_tokens': 517, 'output_tokens': 48, 'total_tokens': 565, 'input_token_details': {'cache_read': 0}})"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##GENERATE THE ANSWER\n",
    "llm.invoke(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3a64d6bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\VishuManjhi\\AppData\\Local\\Temp\\ipykernel_25256\\2556014069.py:5: LangChainDeprecationWarning: The method `BaseRetriever.get_relevant_documents` was deprecated in langchain-core 0.1.46 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  retriever_chain = RunnableLambda(lambda x: retriever.get_relevant_documents(x[\"question\"])) ##wrapped around runnableLambda to get relevant documents\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='Based on the provided text snippets, the main topic appears to be **judgment and decision making**, specifically focusing on logical reasoning and cognitive tasks.  The document includes examples of premises and conclusions in logical arguments, and a section on time preference items.' additional_kwargs={} response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'safety_ratings': []} id='run--d758cd9c-130a-4419-8b80-eae4da43ceef-0' usage_metadata={'input_tokens': 1248, 'output_tokens': 50, 'total_tokens': 1298, 'input_token_details': {'cache_read': 0}}\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "retriever = vectorstore.as_retriever()\n",
    "\n",
    "prompt_template = ChatPromptTemplate.from_template(\"\"\"\n",
    "You are an AI assistant. Use the context below to answer the question.\n",
    "If you don't know the answer, say you don't know.\n",
    "\n",
    "Context:\n",
    "{context}\n",
    "\n",
    "Question:\n",
    "{question}\n",
    "\"\"\")\n",
    "\n",
    "rag_chain = (\n",
    "    {\"context\": retriever_chain, \"question\": RunnablePassthrough()}\n",
    "    | prompt_template\n",
    "    | llm\n",
    ")\n",
    "\n",
    "response = rag_chain.invoke({\n",
    "    \"question\": \"What is the main topic of the pdf?\"\n",
    "})\n",
    "\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "bc8ca562",
   "metadata": {},
   "outputs": [],
   "source": [
    "##GENERATE STRUCTURED RESPONES USING PYDANTIC  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d511975",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unindent does not match any outer indentation level (<string>, line 10)",
     "output_type": "error",
     "traceback": [
      "  \u001b[36mFile \u001b[39m\u001b[32m<string>:10\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31mrag_chain.invoke(\u001b[39m\n                     ^\n\u001b[31mIndentationError\u001b[39m\u001b[31m:\u001b[39m unindent does not match any outer indentation level\n"
     ]
    }
   ],
   "source": [
    "class ExtractedData(BaseModel):\n",
    "    main_topic: str = Field(..., description=\"The main topic of the PDF document.\")\n",
    "    summary: str = Field(..., description=\"A brief summary of the PDF document.\")\n",
    "    keywords: list[str] = Field(..., description=\"Keywords related to the PDF document.\") \n",
    "    ### we can add source and answer with source like this\n",
    "class AnswerWithSource(BaseModel):\n",
    "    answer: str = Field(..., description=\"The answer to the question.\")\n",
    "    source: str = Field(..., description=\"The full direct text chunk from which the answer was derived.\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "7b29169f",
   "metadata": {},
   "outputs": [],
   "source": [
    "rag_chain = (\n",
    "    {\"context\": retriever_chain, \"question\": RunnablePassthrough()}\n",
    "    | prompt_template\n",
    "    | llm\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4df524a",
   "metadata": {},
   "outputs": [],
   "source": [
    "##GEMINI doesnt support structured output now i got to know :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "474cf746",
   "metadata": {},
   "outputs": [],
   "source": [
    "##but we will manually prompt the model to give structured output to JSON then to pydanctic model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66c46846",
   "metadata": {},
   "outputs": [],
   "source": [
    "##from pydantic import BaseModel\n",
    "##from typing import List,Optional\n",
    "\n",
    "##class ExtractedData(BaseModel):\n",
    "  #  title: str\n",
    "   # authors: list[str]\n",
    "    #abstract: str\n",
    "    #keywords: list[str]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffe9ebcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "#prompt_template = ChatPromptTemplate.from_template(\"\"\"\n",
    "#Extract the following structured data from the context.\n",
    "\n",
    "#Respond in valid JSON format with keys: \"title\", \"authors\" (as list), and \"abstract\".\n",
    "\n",
    "#Context:\n",
    "#{context}\n",
    "\n",
    "#Question:\n",
    "#{question}\n",
    "#\"\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "20f20861",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever_chain = RunnableLambda(lambda x: retriever.get_relevant_documents(x[\"question\"]))\n",
    "\n",
    "rag_chain = (\n",
    "    {\"context\": retriever_chain, \"question\": RunnablePassthrough()}\n",
    "    | prompt_template\n",
    "    | llm  # this is your Gemini LLM\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "bb85fb11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Error parsing structured output: Expecting value: line 1 column 1 (char 0)\n",
      "Raw response: ```json\n",
      "{\n",
      "  \"title\": null,\n",
      "  \"authors\": [],\n",
      "  \"abstract\": null\n",
      "}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "response = rag_chain.invoke({\n",
    "    \"question\": \"Extract the title, authors, and abstract from this paper.\"\n",
    "})\n",
    "\n",
    "# Assuming response.content is a JSON string\n",
    "try:\n",
    "    parsed_data = ExtractedData.parse_obj(json.loads(response.content))\n",
    "    print(parsed_data)\n",
    "except Exception as e:\n",
    "    print(\" Error parsing structured output:\", e)\n",
    "    print(\"Raw response:\", response.content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "1e48015c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_and_parse_llm_output(response, model):\n",
    "    \"\"\"\n",
    "    Cleans LLM response of markdown syntax and parses to Pydantic model.\n",
    "    \n",
    "    Args:\n",
    "        response: LLM response (object with .content or plain string)\n",
    "        model: A Pydantic model (e.g. ExtractedData)\n",
    "    \n",
    "    Returns:\n",
    "        Parsed object or None\n",
    "    \"\"\"\n",
    "    raw = response.content.strip() if hasattr(response, \"content\") else str(response).strip()\n",
    "\n",
    "    # Remove ```json and trailing ```\n",
    "    if raw.startswith(\"```json\"):\n",
    "        raw = raw[len(\"```json\"):].strip()\n",
    "    if raw.endswith(\"```\"):\n",
    "        raw = raw[:-3].strip()\n",
    "\n",
    "    try:\n",
    "        return model.parse_obj(json.loads(raw))\n",
    "    except Exception as e:\n",
    "        print(\"Error parsing LLM output:\", e)\n",
    "        print(\"Cleaned raw output:\", raw)\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "892a7f4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 Raw LLM Output Before Cleaning:\n",
      " ```json\n",
      "{\"title\": null, \"authors\": [], \"abstract\": null}\n",
      "```\n",
      "❌ Error parsing LLM output: 3 validation errors for ExtractedData\n",
      "title\n",
      "  Input should be a valid string [type=string_type, input_value=None, input_type=NoneType]\n",
      "    For further information visit https://errors.pydantic.dev/2.11/v/string_type\n",
      "abstract\n",
      "  Input should be a valid string [type=string_type, input_value=None, input_type=NoneType]\n",
      "    For further information visit https://errors.pydantic.dev/2.11/v/string_type\n",
      "keywords\n",
      "  Field required [type=missing, input_value={'title': None, 'authors': [], 'abstract': None}, input_type=dict]\n",
      "    For further information visit https://errors.pydantic.dev/2.11/v/missing\n",
      "👉 Cleaned raw output: {\"title\": null, \"authors\": [], \"abstract\": null}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\VishuManjhi\\AppData\\Local\\Temp\\ipykernel_25256\\35413278.py:24: PydanticDeprecatedSince20: The `parse_obj` method is deprecated; use `model_validate` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.11/migration/\n",
      "  return model.parse_obj(json.loads(raw))\n"
     ]
    }
   ],
   "source": [
    "response = rag_chain.invoke({    \"question\": \"Extract the title, authors, and abstract from this research paper.\"\n",
    "})\n",
    "\n",
    "##TRIED BUT JSON DIDNT WORK\n",
    "\n",
    "parsed_data = clean_and_parse_llm_output(response, ExtractedData)\n",
    "if parsed_data:\n",
    "    print(\"Title:\", parsed_data.title)\n",
    "    print(\"Authors:\", parsed_data.authors)\n",
    "    print(\"Abstract:\", parsed_data.abstract)\n",
    "    print(\"Keywords:\", parsed_data.keywords)        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fafc24dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📄 Raw LLM Response:\n",
      " ```json\n",
      "{\n",
      "  \"title\": null,\n",
      "  \"authors\": [],\n",
      "  \"abstract\": null\n",
      "}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "response = rag_chain.invoke({\n",
    "    \"question\": \"Extract the title, authors, and abstract from this research paper.\"\n",
    "})\n",
    "\n",
    "print(\"Raw LLM Response:\\n\", response.content if hasattr(response, \"content\") else response)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
